<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-06-18T14:06:19+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">오류동 개발자</title><subtitle>개발과 일상적인 이야기들</subtitle><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><entry><title type="html">Kafka’s exactly-once delivery</title><link href="http://localhost:4000/apache-kafka/kakfa-exactly-once-delivery/" rel="alternate" type="text/html" title="Kafka’s exactly-once delivery" /><published>2021-06-18T00:00:00+09:00</published><updated>2021-06-18T00:00:00+09:00</updated><id>http://localhost:4000/apache-kafka/kakfa-exactly-once-delivery</id><content type="html" xml:base="http://localhost:4000/apache-kafka/kakfa-exactly-once-delivery/">&lt;p&gt;Kafka에서 메시지를 중복이나 누락 없이 순서대로 전달되도록 보증하려면 어떻게 해야할까?&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-messaging-sementics&quot;&gt;1. Messaging sementics&lt;/h2&gt;
&lt;p&gt;카프카와 같은 메시징 시스템은 특정 수준의 메시지 보증 전략을 가지고 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;at-most-once&lt;/strong&gt; : 실패나 타임아웃 등이 발생하면 메시지를 버릴 수 있다. 데이터가 일부 누락되더라도 영향이 없는 경우엔 대량처리 및 짧은 주기의 전송 서비스에 유용할 수 있다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;exactly-once&lt;/strong&gt; : 메시지가 정확하게 한 번만 전달되는 것을 보장한다. 손실이나 중복 없이, 순서대로 메시지를 전송하는 것은 구현 난이도가 높고 비용이 많이 든다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;at-least-once&lt;/strong&gt; : 메시지가 최소 1번 이상 전달되는 것을 보장한다. 실패나 타임아웃 등이 발생하면 메시지를 다시 전송하며, 이 경우엔 동일한 메시지가 중복으로 처리될 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;exactly-once가 가장 이상적인 메시지 처리 방식이지만 난이도와 비용으로 인해 at-least-once로 타협하는 경우가 보편적이다. Kafka의 경우 at-least-once를 보장하며 일정 버전 이후에서만 옵션을 통해 exactly-once를 적용할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-kafka의-at-least-once-구현&quot;&gt;2. Kafka의 at-least-once 구현&lt;/h2&gt;

&lt;p&gt;Kafka의 경우 Producer가 메시지를 전송하고 나서 Broker로부터 ack를 받는 수준을 조절함으로써 &lt;strong&gt;at-least-once&lt;/strong&gt;를 보장할 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ack=0&lt;/strong&gt; : Producer가 메시지 전송 후, ack를 기다리지 않고 바로 다음 메시지를 전송한다. 만약 Broker가 다운된다면 이 기간 동안 전송된 메시지들은 모두 손실된다. 메시지가 손실되더라도 빠른 전송이 필요한 경우에 사용할 수 있다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ack=1&lt;/strong&gt; : Producer가 메시지 전송 후, partition leader로부터 일정시간 ack를 기다린다. 손실 가능성이 적고 적당한 전송 속도를 가지게 된다. ack 전송 직후 partition leader의 Broker가 follower들이 복사해가기 전에 다운되면 해당 메시지는 손실된다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ack=all&lt;/strong&gt; : Producer가 메시지 전송 후, partition의 leader, follower 모두로부터 ack를 기다린다. 손실이 없지만 전송 속도가 느리다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-kafka에서-메시지가-중복-처리되는-경우&quot;&gt;3. Kafka에서 메시지가 중복 처리되는 경우&lt;/h2&gt;

&lt;p&gt;Kafka에서 메시지들은 순차적으로 증가하는 offset 값을 가지고 순서대로 추가된다. 
&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/hadoop/img/kafka_sequence_of_offset.png&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Producer는 Kafka에 메시지를 입력하고, Consumer는 메시지를 읽어 DB 등의 저장소에 저장한다. 이 경우 다음과 같은 파이프라인이 형성된다.
&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/hadoop/img/kafka_producer_to_consumer_pipeline.png&quot; width=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 파이프라인에서 메시지가 중복 처리되는 경우, 즉 at-least-once에 해당하는 경우는 다음과 같이 2가지가 있다.&lt;/p&gt;

&lt;h3 id=&quot;3-1-producer-broker-사이의-ack-소실&quot;&gt;3-1. Producer-Broker 사이의 ack 소실&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Producer는 Broker에 메시지를 전송하고 ack를 수신받는다.&lt;/li&gt;
  &lt;li&gt;만약 네트워크 상에서 ack가 소실/지연되어 수신받는데에 실패할 경우, Producer는 메시지 전송이 실패했다고 판단하여 재전송하게 된다.&lt;/li&gt;
  &lt;li&gt;즉, 동일한 메시지가 중복 전송될 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-2-consumer-side의-offset-갱신-실패&quot;&gt;3-2. Consumer side의 offset 갱신 실패&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Consumer가 메시지를 읽고 DB에 저장한 후에 offset을 갱신하기 전에 장애가 발생할 경우, Consumer는 재시작되었을 때 갱신되지 않은 offset을 기준으로 메시지를 읽어오게 된다.&lt;/li&gt;
  &lt;li&gt;즉, 이미 DB에 저장된 메시지를 중복으로 가져오게 된다.&lt;/li&gt;
  &lt;li&gt;예시) Spark Streaming의 Receiver 기반 모델에서 WAL을 사용하는 경우&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-producer-side의-exactly-once-구현&quot;&gt;4. Producer side의 exactly-once 구현&lt;/h2&gt;

&lt;p&gt;Kafka는 at-least-once 방식을 지원했으나, 0.11.0.0 이상부터는 트랜잭션을 적용하여 exactly-once를 구현할 수 있다. Producer가 트랜잭션에서 처리한 데이터의 offset을 커밋함으로써, Consumer에 정확하게 메시지를 전달할 을 수 있다.&lt;/p&gt;

&lt;p&gt;Producer side에서 트랜잭션을 적용하려면 Consumer side에서도 트랜잭션 기반으로 메시지를 읽어야 한다. 즉, Consumer 에도 트랜잭션 API를 적용해야 한다.&lt;/p&gt;

&lt;h3 id=&quot;4-1-transaction-api-in-producer&quot;&gt;4-1. Transaction API in Producer&lt;/h3&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;KafkaProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;configs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;TOPIC_NAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;data&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;initTransactions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// 트랜잭션 준비&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;beginTransaction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// 트랜잭션 시작&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;// 메시지 전송&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;flush&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;commitTransaction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 트랜잭션 커밋&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;initTransactions()로 트랜잭션을 준비한다.&lt;/li&gt;
  &lt;li&gt;beginTransaction()과 commitTransaction() 사이에 send() 메소드가 위치하여 전송된 메시지가 커밋되도록 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-2-transaction-api-in-consumer&quot;&gt;4-2. Transaction API in Consumer&lt;/h3&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;configs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConsumerConfig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ENABLE_AUTO_COMMIT_CONFIG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;           &lt;span class=&quot;c1&quot;&gt;// 명시적 오프셋 커밋&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;configs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConsumerConfig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ISOLATION_LEVEL_CONFIG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;read_committed&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;// 커밋된 메시지만 읽기&lt;/span&gt;

&lt;span class=&quot;nc&quot;&gt;KafkaConsumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaConsumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;configs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;subscribe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Arrays&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;asList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;TOPIC_NAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;ConsumerRecords&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ofSeconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConsumerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{}&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;commitSync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ISOLATION_LEVEL_CONFIG&lt;/code&gt; 옵션을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read_committed&lt;/code&gt;로 설정하여 트랜잭션이 완벽하게 완료된 메시지만 읽어온다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-3-transaction-status&quot;&gt;4-3. Transaction status&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;./kafka-console-consumer.sh &lt;span class=&quot;nt&quot;&gt;--consumer&lt;/span&gt;.config consumer.config &lt;span class=&quot;nt&quot;&gt;--formatter&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;kafka.coordinator.transaction.TransactionLog&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\$&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;TransactionLogMessageFormatter&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--bootstrap-server&lt;/span&gt; localhost:9092 &lt;span class=&quot;nt&quot;&gt;--topic&lt;/span&gt; __transaction_state &lt;span class=&quot;nt&quot;&gt;--from-beginning&lt;/span&gt;
13c2df10-1a3c-4024-b28d-d155e24b941a::TransactionMetadata&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;transactionalId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;13c2df10-1a3c-4024-b28d-d155e24b941a, &lt;span class=&quot;nv&quot;&gt;producerId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1000, &lt;span class=&quot;nv&quot;&gt;producerEpoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;28, &lt;span class=&quot;nv&quot;&gt;txnTimeoutMs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;60000, &lt;span class=&quot;nv&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Ongoing, &lt;span class=&quot;nv&quot;&gt;pendingState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;None, &lt;span class=&quot;nv&quot;&gt;topicPartitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Set&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;test-1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, &lt;span class=&quot;nv&quot;&gt;txnStartTimestamp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1594967312702, &lt;span class=&quot;nv&quot;&gt;txnLastUpdateTimestamp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1594967312702&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
13c2df10-1a3c-4024-b28d-d155e24b941a::TransactionMetadata&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;transactionalId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;13c2df10-1a3c-4024-b28d-d155e24b941a, &lt;span class=&quot;nv&quot;&gt;producerId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1000, &lt;span class=&quot;nv&quot;&gt;producerEpoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;28, &lt;span class=&quot;nv&quot;&gt;txnTimeoutMs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;60000, &lt;span class=&quot;nv&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;PrepareCommit, &lt;span class=&quot;nv&quot;&gt;pendingState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;None, &lt;span class=&quot;nv&quot;&gt;topicPartitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Set&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;test-1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, &lt;span class=&quot;nv&quot;&gt;txnStartTimestamp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1594967312702, &lt;span class=&quot;nv&quot;&gt;txnLastUpdateTimestamp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1594967312712&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
13c2df10-1a3c-4024-b28d-d155e24b941a::TransactionMetadata&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;transactionalId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;13c2df10-1a3c-4024-b28d-d155e24b941a, &lt;span class=&quot;nv&quot;&gt;producerId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1000, &lt;span class=&quot;nv&quot;&gt;producerEpoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;28, &lt;span class=&quot;nv&quot;&gt;txnTimeoutMs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;60000, &lt;span class=&quot;nv&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;CompleteCommit, &lt;span class=&quot;nv&quot;&gt;pendingState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;None, &lt;span class=&quot;nv&quot;&gt;topicPartitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Set&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;, &lt;span class=&quot;nv&quot;&gt;txnStartTimestamp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1594967312702, &lt;span class=&quot;nv&quot;&gt;txnLastUpdateTimestamp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1594967312713&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__transaction_state&lt;/code&gt; 토픽은 Producer가 전송한 각 트랜잭션의 상태 정보를 기록하며 Consumer가 이 정보를 참조한다.&lt;/li&gt;
  &lt;li&gt;트랜잭션의 상태가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Ongoing&lt;/code&gt; -&amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PrepareCommit&lt;/code&gt; -&amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CompleteCommit&lt;/code&gt;순서로 갱신된다.&lt;/li&gt;
  &lt;li&gt;커밋 완료 상태의 트랜잭션에 대해서만 메시지를 읽어올 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-4-broker-offset&quot;&gt;4-4. Broker offset&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;./kafka-dump-log.sh &lt;span class=&quot;nt&quot;&gt;--files&lt;/span&gt; /path/to/kafka/kafka_2.12-2.5.0/data/test-1/00000000000000000000.log &lt;span class=&quot;nt&quot;&gt;--deep-iteration&lt;/span&gt;
baseOffset: 16 lastOffset: 16 count: 1 baseSequence: 0 lastSequence: 0 producerId: 1000 producerEpoch: 21 partitionLeaderEpoch: 0 isTransactional: &lt;span class=&quot;nb&quot;&gt;true &lt;/span&gt;isControl: &lt;span class=&quot;nb&quot;&gt;false &lt;/span&gt;position: 1680 CreateTime: 1594965813907 size: 122 magic: 2 compresscodec: NONE crc: 3909138376 isvalid: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;
| offset: 16 CreateTime: 1594965813907 keysize: &lt;span class=&quot;nt&quot;&gt;-1&lt;/span&gt; valuesize: 54 sequence: 0 headerKeys: &lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt;
baseOffset: 17 lastOffset: 17 count: 1 baseSequence: &lt;span class=&quot;nt&quot;&gt;-1&lt;/span&gt; lastSequence: &lt;span class=&quot;nt&quot;&gt;-1&lt;/span&gt; producerId: 1000 producerEpoch: 21 partitionLeaderEpoch: 0 isTransactional: &lt;span class=&quot;nb&quot;&gt;true &lt;/span&gt;isControl: &lt;span class=&quot;nb&quot;&gt;true &lt;/span&gt;position: 1802 CreateTime: 1594965813942 size: 78 magic: 2 compresscodec: NONE crc: 3102183917 isvalid: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;
| offset: 17 CreateTime: 1594965813942 keysize: 4 valuesize: 6 sequence: &lt;span class=&quot;nt&quot;&gt;-1&lt;/span&gt; headerKeys: &lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; endTxnMarker: COMMIT coordinatorEpoch: 0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;위 예시에선 토픽의 특정 파티션에 메시지가 입력되어 16번, 17번 offset에 각각 기록되었다.&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th&gt; &lt;/th&gt;
          &lt;th&gt;isTransactional&lt;/th&gt;
          &lt;th&gt;isControl&lt;/th&gt;
          &lt;th&gt;endTxnMarker&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;16번 offset&lt;/td&gt;
          &lt;td&gt;true&lt;/td&gt;
          &lt;td&gt;false&lt;/td&gt;
          &lt;td&gt;-&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td&gt;17번 offset&lt;/td&gt;
          &lt;td&gt;true&lt;/td&gt;
          &lt;td&gt;true&lt;/td&gt;
          &lt;td&gt;COMMIT&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Producer는 메시지를 전송하고(16번 offset) 트랜잭션이 완료되면 COMMIT 메시지를 입력한다(17번 offset).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;즉, 한 트랜잭션에 대해 실제 메시지와 COMMIT 메시지를 위해 offset이 2개 소모되었다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Consumer는 데이터를 가져갈 때 &lt;strong&gt;트랜잭션의 실제 데이터인 16번 offset만 가져가고, COMMIT 명시 데이터인 17번 offset은 무시&lt;/strong&gt;한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-consumer-side의-exactly-once-구현&quot;&gt;5. Consumer side의 exactly-once 구현&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Consumer에서 메시지를 읽고 나서 &lt;strong&gt;DB에 저장하는 단계&lt;/strong&gt;와 &lt;strong&gt;offset을 갱신하는 단계&lt;/strong&gt; 사이에서 장애가 발생할 경우에 메시지 중복 처리가 발생한다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/dhkdn9192/data_engineer_should_know/blob/master/interview/hadoop/kafka_sparkstreaming_integration.md&quot;&gt;Kafka + Spark Streaming Integration의 Receiver-based Approach&lt;/a&gt; 의 예시에선 Receiver와 WAL을 제거하고 directStream 및 자체 offset checkpoint (with HDFS/HBase)를 사용하여 동일 메시지를 중복으로 읽지 않도록 할 수 있다. (자세한 건 링크 참조)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;6-conclusion&quot;&gt;6. Conclusion&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Kafka는 0.11.0.0 버전부터 트랜잭션을 이용한 exactly-once를 지원하게 되었다.&lt;/li&gt;
  &lt;li&gt;offset 소모, 약간의 성능저하 등 일정 부분을 희생한 trade-off가 존재한다.&lt;/li&gt;
  &lt;li&gt;파이프라인 전체에 대해 exactly-once를 지원하려면 Kafka 외부의 애플리케이션단에서도 중복 처리 이슈까지 해결되어야 한다. (예: Spark Streaming의 Receiver-based Approach 이슈)&lt;/li&gt;
  &lt;li&gt;데이터 처리에 있어 동일 데이터의 중복이 허용되지 않는 경우엔 exactly-once가 필수적이나, 그렇지 않은 경우에는 기존의 at-least-once를 사용하면 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;https://medium.com/@jaykreps/exactly-once-support-in-apache-kafka-55e1fdd0a35f&lt;/li&gt;
  &lt;li&gt;https://www.joinc.co.kr/w/man/12/Kafka/exactlyonce&lt;/li&gt;
  &lt;li&gt;https://blog.voidmainvoid.net/354&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="apache-kafka" /><category term="kafka" /><summary type="html">Kafka에서 메시지를 중복이나 누락 없이 순서대로 전달되도록 보증하려면 어떻게 해야할까?</summary></entry><entry><title type="html">Spark Streaming에서 Kafka 메시지를 효율적으로 읽으려면?</title><link href="http://localhost:4000/apache-kafka/kafka-consuming-in-sparkstreaming/" rel="alternate" type="text/html" title="Spark Streaming에서 Kafka 메시지를 효율적으로 읽으려면?" /><published>2021-06-16T00:00:00+09:00</published><updated>2021-06-16T00:00:00+09:00</updated><id>http://localhost:4000/apache-kafka/kafka-consuming-in-sparkstreaming</id><content type="html" xml:base="http://localhost:4000/apache-kafka/kafka-consuming-in-sparkstreaming/">&lt;p&gt;컨슈머는 Kafka로부터 메시지를 subscribe하고 처리하여 원하는 저장소에 전달한다. 만약 프로듀서가 토픽에 메시지를 입력하는 속도가 컨슈머의 처리 속도를 초과한다면 어떻게 해야할까? 이 경우엔 여러 컨슈머가 같은 토픽을 subscribe할 수 있도록 컨슈머 그룹를 확장해야 한다.&lt;/p&gt;

&lt;p&gt;모든 컨슈머는 특정 컨슈머 그룹에 소속된다. 만약 같은 그룹의 컨슈머들이 같은 토픽을 subscribe한다면 각 컨슈머는 서로 겹치지 않게 파티션의 데이터를 읽게 된다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-read-kafka--partitions-and-consumers&quot;&gt;1. Read Kafka : Partitions and Consumers&lt;/h2&gt;

&lt;h3 id=&quot;1-1-n-partitions-and-one-consumer&quot;&gt;1-1. N Partitions and One Consumer&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/hadoop/img/kafka_one_consumer_with_multiple_partitions.png&quot; alt=&quot;data_engineer_should_know/kafka_one_consumer_with_multiple_partitions.png at master · dhkdn9192/data_engineer_should_know (github.com)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;컨슈머 그룹 내에 컨슈머가 하나 뿐일 경우, 혼자서 토픽의 모든 파티션을 subscribe한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-2-partitions--consumers&quot;&gt;1-2. Partitions &amp;gt; Consumers&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/hadoop/img/kafka_two_consumers_with_multiple_partitions.png&quot; alt=&quot;data_engineer_should_know/kafka_two_consumers_with_multiple_partitions.png at master · dhkdn9192/data_engineer_should_know (github.com)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;컨슈머가 2개 일 경우, 각자 파티션 2개씩 subscribe하여 겹치지 않게 메시지를 읽어온다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-3-partitions--consumers&quot;&gt;1-3. Partitions = Consumers&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/hadoop/img/kafka_n_consumers_n_partitions.png&quot; alt=&quot;data_engineer_should_know/kafka_n_consumers_n_partitions.png at master · dhkdn9192/data_engineer_should_know (github.com)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;파티션 수와 컨슈머 수가 동일할 경우, 일대일 연결로 메시지를 읽어온다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-4-partitions--consumers&quot;&gt;1-4. Partitions &amp;lt; Consumers&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/hadoop/img/kafka_more_consumers.png&quot; alt=&quot;data_engineer_should_know/kafka_more_consumers.png at master · dhkdn9192/data_engineer_should_know (github.com)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;만약 컨슈머 수가 파티션 수보다 많다면, 일대일 연결이 되지 못한 컨슈머는 메시지를 읽지 못하고 idle 상태가 된다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-5-another-consumer-group&quot;&gt;1-5. Another Consumer Group&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/hadoop/img/kafka_multiple_consumer_groups.png&quot; alt=&quot;data_engineer_should_know/kafka_multiple_consumer_groups.png at master · dhkdn9192/data_engineer_should_know (github.com)&quot; /&gt;&lt;/p&gt;

&lt;p&gt;같은 토픽을 subscribe하더라도 컨슈머 그룹이 서로 다르다면 서로의 subscribe 정보에 상관 없이 메시지를 처음부터 읽어오게 된다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-spark-streaming에서-kafka-메시지-읽기&quot;&gt;2. Spark Streaming에서 Kafka 메시지 읽기&lt;/h2&gt;

&lt;p&gt;Spark Streaming 애플리케이션이 서로 다른 Kafka 토픽 4개로부터 메시지를 읽어야 한다. 각 토픽은 모두 파티션 수가 3개 이다. 어떻게 해야 Kafka 파티션 수와 컨슈머 수가 일대일 매핑이 될 수 있을까? (Executor의 core 수는 Kafka 파티션을 읽기 위한 것만 고려)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Kafka의 각 파티션은 Spark Streaming Job의 각 core와 매핑된다&lt;/strong&gt;. (Executor와 매핑되는게 아니다!)&lt;/li&gt;
  &lt;li&gt;토픽별 파티션 수가 3개, 토픽의 수는 4개 이므로 읽어야 할 파티션의 수는 총 12개이다.&lt;/li&gt;
  &lt;li&gt;따라서 전체 코어수는 12개여야 한다.&lt;/li&gt;
  &lt;li&gt;코어 수 12개를 구성하는 방법은 다음과 같이 2가지 방법이 있다.
    &lt;ul&gt;
      &lt;li&gt;(1) Executor 1개에 core를 12개 할당 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.executor.instances=1&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.executor.cores=12&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;(2) Executor 12개에 core를 1개씩 할당 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.executor.instances=12&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.executor.cores=1&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;https://oreilly.com/library/view/kafka-the-definitive/9781491936153/ch04.html&lt;/li&gt;
  &lt;li&gt;https://stackoverflow.com/questions/55474645/how-to-optimize-number-of-executor-instances-in-spark-structured-streaming-app&lt;/li&gt;
  &lt;li&gt;https://community.cloudera.com/t5/Support-Questions/What-s-the-right-number-of-cores-and-executors-for-a-spark/m-p/61943&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="apache-kafka" /><category term="spark" /><category term="kafka" /><summary type="html">컨슈머는 Kafka로부터 메시지를 subscribe하고 처리하여 원하는 저장소에 전달한다. 만약 프로듀서가 토픽에 메시지를 입력하는 속도가 컨슈머의 처리 속도를 초과한다면 어떻게 해야할까? 이 경우엔 여러 컨슈머가 같은 토픽을 subscribe할 수 있도록 컨슈머 그룹를 확장해야 한다.</summary></entry><entry><title type="html">Java : String vs StringBuffer, StringBuilder</title><link href="http://localhost:4000/computer_science/java-stringbuffer-stringbuilder/" rel="alternate" type="text/html" title="Java : String vs StringBuffer, StringBuilder" /><published>2021-06-14T00:00:00+09:00</published><updated>2021-06-14T00:00:00+09:00</updated><id>http://localhost:4000/computer_science/java-stringbuffer-stringbuilder</id><content type="html" xml:base="http://localhost:4000/computer_science/java-stringbuffer-stringbuilder/">&lt;p&gt;Java String으로 문자열 연산을 수행하기 위해 아래와 같은 쿼리를 수행한다고 가정해보자&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myQuery&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;myQuery&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;select * &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;myQuery&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;from atable &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;myQuery&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;limit 100; &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;최종적으로 myQuery 문자열에 저장되는 값은 “select * from atable limit 100;” 이라는 sql 쿼리문이다. 그러나 각 라인을 수행하면서 각각의 부분 문자열 객체들을 생성해야하고 이는 연산 후에 곧바로 사용되지 않는 garbage가 된다. &lt;strong&gt;garbage가 많이 생성될 수록 메모리 사용량도 늘어나고, GC 또한 빈번하게 발생하므로 속도도 느려지게된다&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;다음처럼 매번 다른 메모리 주소 상에 새로운 객체가 저장된다. 즉, 직전까지의 객체는 garbage가 된다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;메모리 주소&lt;/th&gt;
      &lt;th&gt;값&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;“select * “&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;150&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;“select * from atable”&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;200&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;“select * from atable limit 100;”&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;string-대신-stringbuffer-stringbuilder&quot;&gt;String 대신 StringBuffer, StringBuilder&lt;/h2&gt;

&lt;p&gt;위의 예시를 Java의 StringBuffer 또는 StringBuilder를 사용할 경우 아래처럼 작성할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;StringBuffer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strBuff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;StringBuffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;strBuff&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;select * &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;strBuff&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;from atable &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;strBuff&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;limit 100; &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myQuery&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strBuff&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;StringBuffer나 StringBuilder는 String과는 달리 &lt;strong&gt;새로운 객체를 생성하지 않는다&lt;/strong&gt;. append() 연산을 통해 기존 객체에 데이터를 추가한다. 매 연산마다 garbage가 생성되지 않으므로 GC 또한 빈번하게 발생하지 않는다.&lt;/p&gt;

&lt;p&gt;메모리 상에 데이터가 저장될 때에는 다음처럼 동일한 주소의 객체에 추가된다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;메모리 주소&lt;/th&gt;
      &lt;th&gt;값&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;“select * “&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;“select * from atable”&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;“select * from atable limit 100;”&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;stringbuffer-vs-stringbuilder&quot;&gt;StringBuffer vs StringBuilder&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;StringBuffer는 thread-safe하게 설계되어 여러개의 thread가 접근하는 환경에서도 사용할 수 있다.&lt;/li&gt;
  &lt;li&gt;StringBuilder는 단일 thread에서의 안전성만 보전하므로 여러개의 thread가 접근하면 문제가 발생할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;결론&quot;&gt;결론&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;String은 가급적이면 문자열 연산이 없는 경우에 사용한다.&lt;/li&gt;
  &lt;li&gt;StringBuffer는 thread-safe한 프로그래밍이 필요한 경우(static 선언된 문자열을 변경하는 등)에 사용한다.&lt;/li&gt;
  &lt;li&gt;StringBuilder는 thread-safe 여부와 관계 없이 프로그래밍할 경우(메소드 내에서 선언된 문자열을 변경한는 등)에 사용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;도서 “자바 성능 튜닝 이야기”, 인사이트, 이상민 지음&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="computer_science" /><category term="jvm" /><category term="gc" /><category term="java" /><summary type="html">Java String으로 문자열 연산을 수행하기 위해 아래와 같은 쿼리를 수행한다고 가정해보자</summary></entry><entry><title type="html">Kafka + Spark Streaming Integration</title><link href="http://localhost:4000/apache-spark/apache-kafka/kafka-sparkstreaming-integration/" rel="alternate" type="text/html" title="Kafka + Spark Streaming Integration" /><published>2021-06-08T00:00:00+09:00</published><updated>2021-06-08T00:00:00+09:00</updated><id>http://localhost:4000/apache-spark/apache-kafka/kafka-sparkstreaming-integration</id><content type="html" xml:base="http://localhost:4000/apache-spark/apache-kafka/kafka-sparkstreaming-integration/">&lt;p&gt;Spark Streaming과 Kafka를 연동하는 방법에는 크게 2가지가 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Receiver-based Approach&lt;/li&gt;
  &lt;li&gt;Direct Approach (No Receivers)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-receiver-based-approach&quot;&gt;1. Receiver-based Approach&lt;/h2&gt;

&lt;p&gt;이 통합 방식에서는 데이터 전달 과정에서 더 나은 &lt;strong&gt;Fault-tolerance 수준을 보장&lt;/strong&gt;하기 위해 Spark 1.2부터 도입된 &lt;strong&gt;Write Ahead Log&lt;/strong&gt; (&lt;strong&gt;WAL&lt;/strong&gt;)를 사용한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Spark Executor에 존재하는 Receiver가 Kafka로부터 데이터를 consume한다. Kafka의 high-level consumer API를 사용한다.&lt;/li&gt;
  &lt;li&gt;수신된 데이터는 WAL에 저장된다(HDFS)&lt;/li&gt;
  &lt;li&gt;WAL에 기록이 완료되면, Receiver는 Zookeeper 상의 Kafka offsetㅇ르 업데이트한다.&lt;/li&gt;
  &lt;li&gt;장애가 발생할 경우, WAL의 기록을 읽어 데이터가 손실되지 않도록 복구한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/hadoop/img/kafka_sparkstreaming_receiver_approach.png&quot; alt=&quot;kafka_sparkstreaming_receiver_approach&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Receiver-based Approach는 데이터의 손실은 막을 수 있지만 장애가 발생하면 데이터가 두 번 이상 중복으로 처리될 수 있다는 문제가 있다. 즉, &lt;strong&gt;at-least-once&lt;/strong&gt; 방식이다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Receiver가 WAL에 기록을 완료한 뒤 Zookeeper의 offset을 업데이트하기 전에 장애가 발생&lt;/li&gt;
  &lt;li&gt;Receiver는 다시 Kafka를 consume 할 때 Zookeeper의 업데이트되지 않은 offset을 참조&lt;/li&gt;
  &lt;li&gt;이렇게 읽어온 데이터는 이미 WAL에 기록되어 있으므로 같은 데이터를 두 번 처리하게 됨&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-direct-approach-no-receivers&quot;&gt;2. Direct Approach (No Receivers)&lt;/h2&gt;

&lt;p&gt;위와 같은 문제 때문에 Spark 1.3부터 Direct approach가 도입되었다. Receiver와 WAL을 사용하지 않으며, offset을 Zookeeper에 갱신하지 않고 직접 checkpoint로 관리한다. Receiver approach와 비교하여 아래와 같은 이점을 갖는다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Simplified Prallelism&lt;/strong&gt; : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;directStream&lt;/code&gt; 은 Kafka partition 수만큼 RDD partition을 생성해준다. 따라서 여러개의 input Kafka stream을 생성하여 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;union&lt;/code&gt; 해줄 필요가 없다. 덕분에 사용하기 쉽고 설정하기도 용이하다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Efficiency&lt;/strong&gt; : Receiver approach에선 WAL 사용으로 인해 데이터가 중복 처리되는 비효율 문제가 있었다. Direct approach에선 Receiver가 없으므로 WAL 또한 사용하지 않는다. 장애가 생길 경우엔 Kafka로부터 손실된 메시지를 가져온다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Exactly-once semantics&lt;/strong&gt; : offset을 Spark Streaming이 직접 &lt;strong&gt;checkpoint&lt;/strong&gt;를 통해 관리하며 Zookeeper를 사용하지 않는다. 이로 인해 장애가 발생하더라도 Spark Streaming과 Zookeeper/Kafka 사이의 inconsistency가 생기지 않는다. 즉, &lt;strong&gt;exactly-once&lt;/strong&gt; 가 보장된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/hadoop/img/kafka_sparkstreaming_direct_approach.png&quot; alt=&quot;kafka_sparkstreaming_direct_approach&quot; /&gt;&lt;/p&gt;

&lt;p&gt;반면, Zookeeper를 통해 offset이 관리되지 않으므로 다음과 같은 단점을 가진다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;전통적으로 Zookeeper를 사용하는 Kafka 모니터링 도구에서 Spark Streaming이 consume하고 있는 offset을 볼 수 없다. offset을 Zookeeper에 기록하지 않고 checkpoint를 통해 자체적으로 관리하기 때문이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;https://tommypagy.tistory.com/155&lt;/li&gt;
  &lt;li&gt;https://spark.apache.org/docs/2.4.6/streaming-kafka-0-8-integration.html&lt;/li&gt;
  &lt;li&gt;https://databricks.com/blog/2015/03/30/improvements-to-kafka-integration-of-spark-streaming.html&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="apache-spark" /><category term="apache-kafka" /><category term="spark" /><category term="kafka" /><category term="spark-streaming" /><summary type="html">Spark Streaming과 Kafka를 연동하는 방법에는 크게 2가지가 있다.</summary></entry><entry><title type="html">Python의 GIL</title><link href="http://localhost:4000/computer_science/python-gil/" rel="alternate" type="text/html" title="Python의 GIL" /><published>2021-05-30T00:00:00+09:00</published><updated>2021-05-30T00:00:00+09:00</updated><id>http://localhost:4000/computer_science/python-gil</id><content type="html" xml:base="http://localhost:4000/computer_science/python-gil/">&lt;p&gt;CPython에서의 GIL은 여러개의 thread로 Python 코드(bytecode)를 실행할 결우, 단 하나의 thread만이 Python Object에 접근할 수 있도록 제한하는 mutex이다.
이 lock이 필요한 이유는 CPython의 메모리 관리가 thread-safe하지 않기 때문이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;핵심 키워드: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mutex&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;thread-safe&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;synchronized&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;race-condition&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;1-cpython의-메모리-관리-reference-counting&quot;&gt;1. CPython의 메모리 관리: Reference Counting&lt;/h2&gt;
&lt;p&gt;CPython은 각 object별로 reference count를 기록하는 방식으로 메모리를 관리한다.
reference count가 0이되는 object는 메모리 할당이 해제된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Python object의 reference count를 확인하는 예제
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sys&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getrefcount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 출력결과는 3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt;가 최초 생성되었을 때 reference 개수는 1이 됨&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;b&lt;/code&gt;가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt;를 참조하여 reference 개수는 2가 됨&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sys.getrefcount()&lt;/code&gt; 자체가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt;를 참조하므로 출력되는 값은 3&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-cpython의-thread-safe-여부&quot;&gt;2. CPython의 thread-safe 여부&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;thread-safe란 멀티스레드 프로그래밍에서 여러 thread가 객체, 변수 등에 접근하더라도 프로그램의 실행에 문제가 없는 경우를 뜻한다.&lt;/li&gt;
  &lt;li&gt;thread-safe한 코드를 만들기 위해선 mutex 등으로 객체에 lock을 걸어 동시 접근을 막아야 한다.&lt;/li&gt;
  &lt;li&gt;CPython은 C로 만들어졌으며 C에서 thread를 사용할 때의 race condition 문제를 제어하는 것은 온전히 사용자의 몫이다.&lt;/li&gt;
  &lt;li&gt;때문에 CPython은 thead 레벨에서의 메모리 관리가 기본적으로 thread-safe하지 않다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-python에서의-임계영역과-동기화-문제&quot;&gt;3. Python에서의 임계영역과 동기화 문제&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;thread들은 한 process 내에서 같은 힙 메모리 영역을 공유하며 같은 python object들에 접근할 수 있다.&lt;/li&gt;
  &lt;li&gt;즉, thread들에 대해 &lt;strong&gt;각 python object들은 critical section에 해당&lt;/strong&gt;한다.&lt;/li&gt;
  &lt;li&gt;각 python object들의 reference count 값을 여러 thread들이 동시에 접근하여 동기화 문제가 발생할 경우, &lt;strong&gt;메모리 할당이 해제되지 않아 메모리 누수가 발생&lt;/strong&gt;할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;object &quot;foo&quot;를 서로 다른 두 thread가 상호배제 없이 동시에 접근하는 경우
1. thread A가 foo를 참조 =&amp;gt; A가 읽은 reference count는 2
2. thread B가 foo를 참조 =&amp;gt; B가 읽은 reference count는 3
3. thread A가 foo 참조를 해제 =&amp;gt; A는 foo의 reference count 2에서 1을 제거한 값인 1을 저장
4. thread B가 foo 참조를 해제 =&amp;gt; B는 foo의 reference count 3에서 1을 제거한 값인 2를 저장
5. 최종적으로 foo는 참조하는 thread가 없음에도 reference count 2값을 지니게 되어 메모리 할당이 해제되지 않음 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;4-mutex로-임계영역-문제-해결하기&quot;&gt;4. mutex로 임계영역 문제 해결하기&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;위와 같은 문제를 해결하려면 mutex로 상호배제를 적용해야 한다.&lt;/li&gt;
  &lt;li&gt;그러나 각 python object에 mutex로 lock을 거는 것은 매우 비효율적이다.&lt;/li&gt;
  &lt;li&gt;여러개의 mutex를 사용하는 것은 성능적으로도 손해가 많을 뿐만 아니라, deadlock이 발생할 위험이 있다.&lt;/li&gt;
  &lt;li&gt;따라서 Python은 interpreter에 대해 mutex를 걸어 동시에 한 thread만이 python object에 접근할 수 있도록 lock을 거는 방식을 선택했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;https://dgkim5360.tistory.com/entry/understanding-the-global-interpreter-lock-of-cpython&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="computer_science" /><category term="python" /><category term="gil" /><summary type="html">CPython에서의 GIL은 여러개의 thread로 Python 코드(bytecode)를 실행할 결우, 단 하나의 thread만이 Python Object에 접근할 수 있도록 제한하는 mutex이다. 이 lock이 필요한 이유는 CPython의 메모리 관리가 thread-safe하지 않기 때문이다.</summary></entry><entry><title type="html">효율적인 Spark Join 전략</title><link href="http://localhost:4000/apache-spark/spark-join-strategy/" rel="alternate" type="text/html" title="효율적인 Spark Join 전략" /><published>2021-05-29T00:00:00+09:00</published><updated>2021-05-29T00:00:00+09:00</updated><id>http://localhost:4000/apache-spark/spark-join-strategy</id><content type="html" xml:base="http://localhost:4000/apache-spark/spark-join-strategy/">&lt;p&gt;Spark에서 join을 수행하는 경우는 크게 두 가지로 나눌 수 있다. (1) &lt;em&gt;큰 테이블과 작은 테이블을 조인&lt;/em&gt; 또는 (2) &lt;em&gt;큰 테이블과 큰 테이블을 조인&lt;/em&gt;. Spark은 join을 수행하기 위해 Sort Merge Join, Broadcast Join, Shuffle Hash Join 등의 방법을 제공한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;핵심 키워드 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sort merge join&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;shuffle hash join&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;broadcast join&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;straggler&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-sort-merge-join&quot;&gt;1. Sort Merge Join&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/hadoop/img/sort_merge_join.png&quot; alt=&quot;data_engineer_should_know/sort_merge_join.png at master · dhkdn9192/data_engineer_should_know (github.com)&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-1-개요&quot;&gt;1-1. 개요&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;모든 노드 간의 &lt;strong&gt;all-to-all communication&lt;/strong&gt; 방식이다.&lt;/li&gt;
  &lt;li&gt;다음과 같이 두 단계로 수행된다.
    &lt;ul&gt;
      &lt;li&gt;(1) 먼저 실제 join 작업을 수행하기 전에 파티션들을 정렬한다. (이 작업만으로도 비용이 크다)&lt;/li&gt;
      &lt;li&gt;(2) 정렬된 데이터들을 병합하면서 join key가 같은 row들을 join한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sort Merge Join은 Shuffle Hash Join과 비교할 때, 클러스터 내 데이터 이동이 더 적은 경향이 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Spark 2.3부터 디폴트 join 알고리즘으로 사용되고 있다. (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.join.perferSortMergeJoin=true&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1-2-이상적인-성능을-발휘하려면&quot;&gt;1-2. 이상적인 성능을 발휘하려면&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Join될 파티션들이 최대한 같은 곳에 위치해야 한다. 그렇지 않으면 파티션들을 이동시키기 위해 대량의 shuffle이 발생한다.&lt;/li&gt;
  &lt;li&gt;DataFrame의 데이터가 클러스터에 균등하게 분배되어 있어야 한다. 그렇지 않으면 특정 노드에 부하가 집중되고 연산 속도가 느려진다.&lt;/li&gt;
  &lt;li&gt;병렬처리가 이뤄지려면 일정한 수의 고유키가 존재해야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-broadcast-join&quot;&gt;2. Broadcast Join&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/hadoop/img/broadcast_join.png&quot; alt=&quot;data_engineer_should_know/broadcast_join.png at master · dhkdn9192/data_engineer_should_know (github.com)&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-1-개요&quot;&gt;2-1. 개요&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;join할 두 테이블 중 작은 것을 모든 executor에 복사(broadcast)한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;따라서 all-to-all communication 방법으로 shuffle할 필요가 없다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;각 executor에선 보유하고 있는 큰 테이블의 일부와 broadcast된 테이블을 join한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;코드 샘플&lt;/p&gt;

    &lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.functions.broadcast&lt;/span&gt;
  
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;joinDF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;bigDF&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;broadcast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;smallDF&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;joinKey&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-shuffle-hash-join&quot;&gt;3. Shuffle Hash Join&lt;/h2&gt;

&lt;h3 id=&quot;3-1-개요&quot;&gt;3-1. 개요&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;map-reduce에 기반한 join 방식이다.&lt;/li&gt;
  &lt;li&gt;맵 단계에선 join 칼럼을 기준으로 DataFrame을 매핑하고, 리듀스 단계에서 DataFrame을 shuffle하여 join key가 같은 것끼리 join을 수행한다.&lt;/li&gt;
  &lt;li&gt;Spark은 디폴트로 Sort Merge Join을 사용하므로 Shuffle Hash Join을 사용하려면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.join.perferSortMergeJoin&lt;/code&gt; 옵션을 false로 변경해야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;효율적인-join을-방해하는-것들&quot;&gt;효율적인 Join을 방해하는 것들&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Data Skewness&lt;/strong&gt; : join key가 클러스터에 균일하게 분포해 있지 않으면 특정 파티션이 매우 커질 수 있다. 이는 Spark이 parallel하게 연산을 수행하는 것을 방해한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;All-to-all communication&lt;/strong&gt; : broadcast join이 아닐 경우, 두 DF의 데이터 모두에서 대규모 shuffle이 발생한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Limited executor memory&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;data-skewness를-해결하려면&quot;&gt;Data Skewness를 해결하려면?&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Repartitioning&lt;/strong&gt; : 단순히 repartition을 수행하는 것으로 데이터를 파티션들에 더 골고루 분배할 수 있다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Key Salting&lt;/strong&gt; : 근본적으로 파티셔닝되는 칼럼 키값에 salting을 적용하여 키가 고르게 분배될 수 있도록 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;https://towardsdatascience.com/the-art-of-joining-in-spark-dcbd33d693c&lt;/li&gt;
  &lt;li&gt;https://medium.com/datakaresolutions/optimize-spark-sql-joins-c81b4e3ed7da&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="apache-spark" /><category term="spark" /><category term="jvm" /><summary type="html">Spark에서 join을 수행하는 경우는 크게 두 가지로 나눌 수 있다. (1) 큰 테이블과 작은 테이블을 조인 또는 (2) 큰 테이블과 큰 테이블을 조인. Spark은 join을 수행하기 위해 Sort Merge Join, Broadcast Join, Shuffle Hash Join 등의 방법을 제공한다.</summary></entry><entry><title type="html">Garbage Collection 개념 정리</title><link href="http://localhost:4000/computer_science/garbage-collection/" rel="alternate" type="text/html" title="Garbage Collection 개념 정리" /><published>2021-05-29T00:00:00+09:00</published><updated>2021-05-29T00:00:00+09:00</updated><id>http://localhost:4000/computer_science/garbage-collection</id><content type="html" xml:base="http://localhost:4000/computer_science/garbage-collection/">&lt;p&gt;Java에선 메모리 관리를 Garbage Collector가 수행한다. 메모리 상의 불필요한 객체를 찾아 해제하는 역할을 수행한다.&lt;/p&gt;

&lt;p&gt;GC가 발생하는 예시로, Java의 String 연산을 빈번하게 수행하면 불필요한 객체가 많이 생성되므로 잦은 GC를 유발하게 되고 성능이 저하될 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;1-jvm의-runtime-data-area&quot;&gt;1. JVM의 Runtime Data Area&lt;/h2&gt;

&lt;p&gt;JVM의 Runtime Data Area는 다음과 같이 크게 5가지 요소로 구성된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;method area&lt;/li&gt;
  &lt;li&gt;heap&lt;/li&gt;
  &lt;li&gt;Java stacks&lt;/li&gt;
  &lt;li&gt;PC registers&lt;/li&gt;
  &lt;li&gt;Native method stacks&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/computer_science/img/jvm_runtime_data_area_simple.png&quot; alt=&quot;jvm_runtime_data_area&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;1-1-heap-memory&quot;&gt;1-1. Heap memory&lt;/h3&gt;

&lt;p&gt;클래스의 인스턴스, 변수 등의 객체가 저장되는 메모리 영역이다. 여러 thread들이 공유하기 때문에 shared memory라고도 불린다. Heap 메모리의 객체들은 GC의 대상이 된다.&lt;/p&gt;

&lt;h3 id=&quot;1-2-non-heap-memory&quot;&gt;1-2. Non-heap memory&lt;/h3&gt;

&lt;p&gt;Runtime Data Area는 크게 Heap과 Non-heap으로 구분할 수 있다. Non-heap은 Heap 이외의 메모리 영역들을 뜻한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;method area : 메소드 영역은 모든 JVM thread에서 공유한다. 런타임 상수 풀, 메소드, 생성자 코드 등을 포함한다. Java에선 클래스 파일이 constant_pool이라는 정보를 포함하는데 이 constant_pool에 대한 정보를 메소드 영역에서 참조한다.&lt;/li&gt;
  &lt;li&gt;Java stacks (JVM stacks) : thread가 시작할 때 JVM 상에 스택이 생성된다. 스택에는 메소드 호출 정보인 frame, 지역 변수, 임시 결과, 메소드 리턴 관련 정보 등이 저장된다.&lt;/li&gt;
  &lt;li&gt;pc registers : thread들은 각자의 Program Counter 레지스터를 갖는다. thread 들은 Java 코드를 수행할 때 JVM 인스트럭션 주소를 pc 레지스터에 저장한다.&lt;/li&gt;
  &lt;li&gt;native method stacks : Java 코드가 아닌 다른 언어로 된 코드를 실행할 때의 스택 정보를 관리한다. (주로 C언어 등)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;JVM의 Runtime Data Area를 좀 더 구체화하면 아래 이미지와 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/computer_science/img/jvm_runtime_data_area_each_thread.png&quot; alt=&quot;jvm_runatime_data_area_each_thread&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-heap-memory-구조&quot;&gt;2. Heap memory 구조&lt;/h2&gt;

&lt;p&gt;JVM Heap 메모리 구조는 크게 Young 영역(eden, survivor1, survivor2)과 Old 영역으로 구분된다. (Perm 영역은 JDK8부터는 사라진다)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/computer_science/img/JVM-memory-structure2.png&quot; alt=&quot;heap_memory_structure&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Heap 메모리에 객체가 저장되는 방식은 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;새로 생성된 객체는 제일 먼저 eden에 저장된다.&lt;/li&gt;
  &lt;li&gt;eden이 가득 차게 되면 두 survivor 영역 중 비어있는 곳에 옮겨진다.&lt;/li&gt;
  &lt;li&gt;survivor 두 곳 중 하나는 반드시 비어있어야 하며, GC를 수행할 때마다 객체는 두 survivor 사이를 이동하게 된다.&lt;/li&gt;
  &lt;li&gt;이 과정에서 오래 생존한 객체는 Old 영역으로 옮겨진다. (객체의 크기가 survivor보다 클 경우엔 바로 Old 영역으로 이동할 수 있다.)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GC 작업은 Heap 메모리 상에서 사용하지 않는 메모리를 인식하여 자원을 반환하는 일을 수행한다. 만약 GC를 해도 더 이상 사용 가능한 메모리 영역이 없는데 애플리케이션이 계속 메모리를 할당하려고 하면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OutOfMemoryError&lt;/code&gt; 가 발생하여 JVM이 다운될 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;3-gc의-종류&quot;&gt;3. GC의 종류&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Minor GC : Young 영역에서 발생하는 GC&lt;/li&gt;
  &lt;li&gt;Major GC : Old 영역에서 발생하는 GC&lt;/li&gt;
  &lt;li&gt;Full GC : 전체 영역에서 발생하는 GC&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-gc-알고리즘&quot;&gt;4. GC 알고리즘&lt;/h2&gt;

&lt;p&gt;JDK에선 아래와 같은 5가지 GC 방식을 지원한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Serial Collector (시리얼 콜렉터)&lt;/li&gt;
  &lt;li&gt;Parallel Collector (병렬 콜렉터)&lt;/li&gt;
  &lt;li&gt;Parallel Compacting Collector (병렬 콤팩팅 콜렉터)&lt;/li&gt;
  &lt;li&gt;Concurrent Mark-Sweep Collector (CMS 콜렉터)&lt;/li&gt;
  &lt;li&gt;Garbage First Collector (G1 콜렉터)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-1-serial-collector&quot;&gt;4-1. Serial Collector&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Young 영역에 대한 GC와 Old 영역에 대한 GC가 연속적으로 처리된다.&lt;/li&gt;
  &lt;li&gt;하나의 CPU를 사용한다.&lt;/li&gt;
  &lt;li&gt;Minor GC가 이뤄지는 절차는 다음과 같다
    &lt;ol&gt;
      &lt;li&gt;eden이 가득 차게 될 경우, eden의 살아있는 객체과 (from) survivor의 살아있는 객체를 비어있는 (to) survivor로 이동한다.&lt;/li&gt;
      &lt;li&gt;eden과 (from) survivor를 비운다.&lt;/li&gt;
      &lt;li&gt;(to) survivor가 가득 차게 되는 경우, eden과 (from) survivor의 남은 객체는 Old 영역으로 이동한다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Old 영역에 대한 GC는 &lt;strong&gt;Mark-Sweep-Compaction&lt;/strong&gt; 콜렉션 알고리즘을 따른다.
    &lt;ol&gt;
      &lt;li&gt;Old 영역의 살아있는 객체를 식별한다. (Mark)&lt;/li&gt;
      &lt;li&gt;Old 영역의 garbage 객체를 식별한다. (Sweep)&lt;/li&gt;
      &lt;li&gt;Garbage 객체를 지우고 살아있는 객체들을 한 곳으로 모아 컴팩팅한다. (Compaction)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;시리얼 콜렉터는 클라이언트단의 장비 등 대기 시간이 길어도 문제되지 않는 시스템에서 사용된다.&lt;/li&gt;
  &lt;li&gt;사용하려면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-XX:+UseSerialGC&lt;/code&gt; 옵션을 사용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-2-parallel-collector&quot;&gt;4-2. Parallel Collector&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Throughput Collector로도 불린다.&lt;/li&gt;
  &lt;li&gt;시리얼 콜렉터와 달리, Young 영역에서의 GC를 parallel로 처리한다.&lt;/li&gt;
  &lt;li&gt;많은 CPU를 사용하므로 처리량이 많고 GC로 인한 부하를 줄일 수 있다.&lt;/li&gt;
  &lt;li&gt;Old 영역의 GC는 시리얼 콜렉터와 마찬가지로 &lt;strong&gt;Mark-Sweep-Compaction&lt;/strong&gt; 콜렉션 알고리즘을 사용한다.&lt;/li&gt;
  &lt;li&gt;사용하려면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-XX:+UseParallelGC&lt;/code&gt; 옵션을 사용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/computer_science/img/serial_gc_and_parallel_gc.png&quot; alt=&quot;serial_gc_and_parallel_gc&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;4-3-parallel-compacting-collector&quot;&gt;4-3. Parallel Compacting Collector&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Young 영역에 대한 GC는 병렬 콜렉터와 동일하다. (parallel로 처리)&lt;/li&gt;
  &lt;li&gt;Old 영역에 대한 GC는 병렬 콜렉터와 달리 &lt;strong&gt;Mark-Summary-Compaction&lt;/strong&gt; 방식으로 이뤄진다.
    &lt;ol&gt;
      &lt;li&gt;Mark (표시 단계) : 살아있는 객체를 식별하는 단계&lt;/li&gt;
      &lt;li&gt;Summary (종합 단계) : 이전 GC에서 컴팩션된 영역의 살아있는 객체를 조사하는 단계&lt;/li&gt;
      &lt;li&gt;Compaction (컴팩션 단계 ) : 컴팩션을 수행하는 단계&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;시리얼 콜렉터, 병렬 콜렉터의 Mark-Sweep-Compaction과 병렬 컴팩팅 콜렉터의 Mark-Summary-Compaction 차이점은 스윕(Sweep)과 종합(Summary) 단계의 차이로 볼 수 있다.
    &lt;ul&gt;
      &lt;li&gt;Sweep 단계 : 단일 스레드가 Old 영역 전체를 훑는다.&lt;/li&gt;
      &lt;li&gt;Summary 단계 : &lt;strong&gt;여러개의 스레드가 Old 영역을 분리하여 훑는다&lt;/strong&gt;. 또한 수행한 GC에서 컴팩팅된 영역을 별도로 훑는다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;사용하려면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-XX:+UseParallelOldGC&lt;/code&gt; 옵션을 사용하며 스레드 개수는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-XX:ParallelGCThreads=n&lt;/code&gt; 옵션으로 조정할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-4-cms-collector&quot;&gt;4-4. CMS Collector&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Low-latency Collector로도 알려져 있다.&lt;/li&gt;
  &lt;li&gt;Heap 메모리의 크기가 큰 경우에 적합하다.&lt;/li&gt;
  &lt;li&gt;Young 영역에 대한 GC는 병렬 콜렉터와 동일하다.&lt;/li&gt;
  &lt;li&gt;Old 영역에 대한 GC는 다음 단계로 수행된다.
    &lt;ol&gt;
      &lt;li&gt;Initial Mark : 짧은 대기 시간으로 살아있는 객체를 찾는 단계&lt;/li&gt;
      &lt;li&gt;Concurrent Mark : stop-the-world 없이 애플리케이션과 병렬로 동작하면서 살아있는 객체를 표시하는 단계&lt;/li&gt;
      &lt;li&gt;Remark : Concurrent Mark 수행 동안 변경사항이 발생한 객체에 대해서 다시 표시하는 단계&lt;/li&gt;
      &lt;li&gt;Concurrent Sweep : 표시된 garbage들을 정리하는 단계&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;CMS의 일부 단계들은 concurrent로 수행되며 stop-the-world로 인한 일시정이 없이 애플리케이션과 동시에 동작한다. 즉, 기존 GC의 Mark-Sweep-Compaction 절차에서 발생하던 &lt;strong&gt;stop-the-world 일시정지가 여러 단계로 쪼개져서 각 일시정지의 latency가 짧아지게 되었다&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;CMS는 기본적으로 &lt;strong&gt;컴팩션 단계를 거치지 않으므로 단편화가 발생&lt;/strong&gt;할 수 있다.&lt;/li&gt;
  &lt;li&gt;사용하려면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-XX:+UseConcMarkSweepGC&lt;/code&gt; 옵션으로 사용할 수 있으며 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-XX:CMSInitiatingOccupancyFraction=n&lt;/code&gt; 옵션으로 동시병렬을 시작할 시점을 조절할 수 있다.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;동시병렬 모드 실패로 인한 Full GC&lt;/strong&gt;가 발생할 확률을 줄이려면 위 옵션으로 동시병렬 모드 시작 시점을 앞당기거나 Heap 메로리 또는 Old 영역 비율을 늘리는 방법이 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/computer_science/img/cms_collector_process.png&quot; alt=&quot;cms_collector_process&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;4-5-g1gc&quot;&gt;4-5. G1GC&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;CMS 콜렉터를 대체하기 위해 개발된 GC이다.&lt;/li&gt;
  &lt;li&gt;G1GC는 Heap 메모리를 동일한 크기의 여러 region들로 나누고 가상의 바둑판 형태를 구성한다.&lt;/li&gt;
  &lt;li&gt;Young, Old 영역이 linear하게 구성되지 않으며 물리적으로 나누어져 있지도 않다.&lt;/li&gt;
  &lt;li&gt;G1의 Young GC는 다음과 같은 절차로 이뤄진다.
    &lt;ol&gt;
      &lt;li&gt;몇 개 region들을 Young 영역으로 지정한다.&lt;/li&gt;
      &lt;li&gt;Young 영역에서 eden에 해당하는 곳에 객체가 저장된다.&lt;/li&gt;
      &lt;li&gt;Young 영역에 해당되는 region들이 가득 차면 GC를 수행한다.&lt;/li&gt;
      &lt;li&gt;GC를 수행하면서 살아있는 객체들은 survivor에 해당하는 region으로 옮긴다.&lt;/li&gt;
      &lt;li&gt;오래 살아남은 객체는 Old 영역으로 이동된다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;G1의 Old GC는 다음과 같은 절차로 이뤄진다. (STW는 stop-the-world pause가 발생함을 의미)
    &lt;ol&gt;
      &lt;li&gt;Initial Mark (STW) : Survivor 영역(root region) 중 Old 영역을 참조하고 있는 객체들을 표시한다.&lt;/li&gt;
      &lt;li&gt;Root Region Scanning : Old 영역 참조를 위해 Survivor 영역을 스캔한다. 애플리케이션과 동시병렬로 수행되며 Young GC가 발생하기 전에 수행된다.&lt;/li&gt;
      &lt;li&gt;Concurrent Mark : 전체 Heap에 대해 살아있는 객체를 찾는다. 애플리케이션과 동시병렬로 수행되며 Young GC가 발생한다면 잠시 멈춘다.&lt;/li&gt;
      &lt;li&gt;Remark (STW) : Heap의 살아있는 객체에 대한 마킹을 완료한다. 이 때엔 snapshot-at-the-beginning (SATB)이라는 알고리즘을 사용하여 CMS보다 빠르게 동작한다.&lt;/li&gt;
      &lt;li&gt;Cleanup (STW) : 살아있는 객체와 비어있는 region을 식별하고, 비어있는 region을 초기화한다.&lt;/li&gt;
      &lt;li&gt;Copying (STW) : 살아있는 객체들을 비어있는 region으로 모은다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;CMS와 비교하여 다음과 같은 특징을 가진다.
    &lt;ul&gt;
      &lt;li&gt;CMS와 마찬가지로 별도의 컴팩션 단계는 없지만 &lt;strong&gt;살아있는 객체를 비어있는 region으로 모으는(copying) 과정에서 컴팩션을 수행하는 효과&lt;/strong&gt;를 얻을 수 있다.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;region내 garbage 비율에 따라 우선도를 계산&lt;/strong&gt;함으로써 GC로 인한 pause를 예측할 수 있다.&lt;/li&gt;
      &lt;li&gt;CMS처럼 Old GC의 일부 단계가 동시병렬 모드로 수행되므로 GC의 latency가 낮다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Java 9부터 default로 G1GC를 사용하게 되었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/computer_science/img/g1gc_heap_layout.png&quot; alt=&quot;g1gc_heap_layout&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;도서 “자바 성능 튜닝 이야기”, 인사이트, 이상민 지음&lt;/li&gt;
  &lt;li&gt;https://commons.wikimedia.org/wiki/File:Bdb.gif&lt;/li&gt;
  &lt;li&gt;https://d2.naver.com/helloworld/1329&lt;/li&gt;
  &lt;li&gt;https://d2.naver.com/helloworld/37111&lt;/li&gt;
  &lt;li&gt;https://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/index.html&lt;/li&gt;
  &lt;li&gt;https://docs.oracle.com/javase/9/gctuning/garbage-first-garbage-collector.htm#JSGCT-GUID-15921907-B297-43A4-8C48-DC88035BC7CF&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="computer_science" /><category term="jvm" /><category term="gc" /><category term="java" /><summary type="html">Java에선 메모리 관리를 Garbage Collector가 수행한다. 메모리 상의 불필요한 객체를 찾아 해제하는 역할을 수행한다.</summary></entry><entry><title type="html">Spark Executor의 메모리 구조</title><link href="http://localhost:4000/apache-spark/spark_executor_memory_structure/" rel="alternate" type="text/html" title="Spark Executor의 메모리 구조" /><published>2021-05-25T00:00:00+09:00</published><updated>2021-05-25T00:00:00+09:00</updated><id>http://localhost:4000/apache-spark/spark_executor_memory_structure</id><content type="html" xml:base="http://localhost:4000/apache-spark/spark_executor_memory_structure/">&lt;p&gt;Spark 1.6 이상부턴 메모리 관리가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UnifiedMemoryManager&lt;/code&gt; class에 의해 이뤄진다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/hadoop/img/spark_executor_memory_distribution.png&quot; alt=&quot;executor_memory_distribution&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-reserved-memory&quot;&gt;1. Reserved Memory&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;시스템에 의해 관리되는 메모리 영역으로 크기가 300MB로 고정되어 있다.&lt;/li&gt;
  &lt;li&gt;Spark의 internal object들이 저장된다.&lt;/li&gt;
  &lt;li&gt;Executor에 할당해준 메모리가 Reserved Memory 크기의 1.5배 미만이면 “&lt;em&gt;please use larger heap size&lt;/em&gt;“라는 문구와 함께 에러가 발생한다.&lt;/li&gt;
  &lt;li&gt;메모리 사이즈 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;300 MB (고정)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-user-memory&quot;&gt;2. User Memory&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;사용자가 정의한 데이터구조, UDF가 저장되는 공간이다.&lt;/li&gt;
  &lt;li&gt;Spark에 의해 관리되지 않으며 Spark은 User Memory 공간을 인지하지 않는다.&lt;/li&gt;
  &lt;li&gt;Java Heap 메모리에서 Reserved Memory를 제외한 공간 중에서 Spark Memory 가 아닌 나머지 부분이다.&lt;/li&gt;
  &lt;li&gt;메모리 사이즈 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(Java Heap Memory - Reserved Memory) * (1 - spark.memory.fraction)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-spark-memory&quot;&gt;3. Spark Memory&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Spark에 의해 관리되는 메모리 영역이다.&lt;/li&gt;
  &lt;li&gt;join과 같은 연산들이 실행되는 동안의 내부 상태가 저장되거나 broadcast 변수 등이 저장되는 영역이다.&lt;/li&gt;
  &lt;li&gt;cache/persist에 의해 캐싱된 데이터가 저장되는 영역이다.&lt;/li&gt;
  &lt;li&gt;Storage Memory 영역과 Execution Memory의 두 영역으로 나뉜다.&lt;/li&gt;
  &lt;li&gt;메모리 사이즈 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(Java Heap Memory - Reserved Memory) * spark.memory.fraction&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-1-storage-memory&quot;&gt;3-1. Storage Memory&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;cache된 데이터, broadcast 변수가 저장된다.&lt;/li&gt;
  &lt;li&gt;persist 옵션이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MEMORY&lt;/code&gt;이면 이 영역에 데이터가 캐싱된다.&lt;/li&gt;
  &lt;li&gt;캐싱할 공간이 부족하여 오래된 캐시 데이터를 지울 경우엔 &lt;strong&gt;LRU(Least Recently Used) 방식으로 제거&lt;/strong&gt;한다. (즉, 블록이 디스크로 강제 추방될 수 있다.)&lt;/li&gt;
  &lt;li&gt;캐싱된 데이터가 메모리에서 벗어날 경우에는 디스크에 저장되거나 새로 계산되어야 한다.&lt;/li&gt;
  &lt;li&gt;메모리 사이즈 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(Java Heap Memory - Reserved Memory) * spark.memory.fraction * spark.memory.storageFraction&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-2-execution-memory&quot;&gt;3-2. Execution Memory&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Spark이 task를 실행(execute)하는 동안 생성되는 object 들이 저장된다.&lt;/li&gt;
  &lt;li&gt;예시) Hash aggregation step에서 해쉬 테이블을 저장하거나, Map 수행 시 Shuffle intermediate buffer를 저장한다.&lt;/li&gt;
  &lt;li&gt;메모리가 충분하지 않을 경우, 디스크로의 spilling을 지원한다.&lt;/li&gt;
  &lt;li&gt;단, 이 영역의 블록은 다른 task에 의해 강제로 추방될 수는 없다. (Storage Memory와 다른 점)&lt;/li&gt;
  &lt;li&gt;메모리 사이즈 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(Java Heap Memory - Reserved Memory) * spark.memory.fraction * (1 - spark.memory.storageFraction)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-3-storage-memory-vs-execution-memory-비교&quot;&gt;3-3. Storage Memory vs Execution Memory 비교&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Storage Memory는 Execution Memory가 사용되지 않는 경우에만 Execution Memory 영역을 빌릴 수 있다.&lt;/li&gt;
  &lt;li&gt;Execution Memory 역시 Storage Memory가 사용되지 않을 경우 Storage Memory 영역을 빌릴 수 있다.&lt;/li&gt;
  &lt;li&gt;Storage Memory가 점유한 Execution Memory 블록은 Execution이 요청할 경우, &lt;strong&gt;강제로 추방될 수 있다&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Execution Memory가 점유한 Storage Memory 블록은 Storage가 요청하더라도, &lt;strong&gt;강제로 추방될 수 없다&lt;/strong&gt;. (Spark이 Execution의 블록을 release할 때까지 기다려야 한다.)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;em&gt;즉, 블록 추방 우선도는 Storage Memory &amp;lt; Execution Memory라 할 수 있다.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-executor-메모리-할당-예시&quot;&gt;4. Executor 메모리 할당 예시&lt;/h2&gt;

&lt;p&gt;Executor 메모리 설정이 다음 표와 같을 경우, 각 메모리 영역에 할당되는 실제 사이즈 계산&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;conf&lt;/th&gt;
      &lt;th&gt;value&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.executor.memory&lt;/td&gt;
      &lt;td&gt;4g&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.memory.fraction&lt;/td&gt;
      &lt;td&gt;0.75&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.memory.storageFraction&lt;/td&gt;
      &lt;td&gt;0.5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;Reserved Memory : &lt;strong&gt;300MB&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;User Memory : (4096MB - 300MB) * (1 - 0.75) = &lt;strong&gt;949MB&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Spark Memory : (4096MB - 300MB) * 0.75 = &lt;strong&gt;2847MB&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Storage Memory : (4096MB - 300MB) * 0.75 * 0.5 = &lt;strong&gt;1423MB&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Execution Memory : (4096MB - 300MB) * 0.75 * (1 - 0.5) = &lt;strong&gt;1423MB&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;https://medium.com/analytics-vidhya/apache-spark-memory-management-49682ded3d42&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="apache-spark" /><category term="spark" /><category term="java" /><category term="jvm" /><summary type="html">Spark 1.6 이상부턴 메모리 관리가 UnifiedMemoryManager class에 의해 이뤄진다.</summary></entry><entry><title type="html">[YARN] CPU 코어 할당을 위한 스케줄러 설정</title><link href="http://localhost:4000/apache-hadoop/yarn-resource-allocation/" rel="alternate" type="text/html" title="[YARN] CPU 코어 할당을 위한 스케줄러 설정" /><published>2020-09-22T00:00:00+09:00</published><updated>2020-09-22T00:00:00+09:00</updated><id>http://localhost:4000/apache-hadoop/yarn-resource-allocation</id><content type="html" xml:base="http://localhost:4000/apache-hadoop/yarn-resource-allocation/">&lt;h2 id=&quot;1-yarn의-초기-cpu-스케줄링-문제&quot;&gt;1. YARN의 초기 CPU 스케줄링 문제&lt;/h2&gt;
&lt;p&gt;Hadoop 클러스터를 처음 구축하면 애플리케이션을 제출할 때 CPU 코어 수가 원하는대로 할당되지 않는 문제를 겪게 된다.
아래와 같이 yarn-client 모드로 SparkSession을 생성하는 예시를 보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SparkSession&lt;/span&gt; \
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;builder&lt;/span&gt; \
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;appName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Spark_Example&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;master&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;yarn-client&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark.executor.instances&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark.executor.memory&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;10g&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark.executor.cores&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;5&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getOrCreate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.executor.cores&lt;/code&gt; 설정으로 executor 당 5개 코어를 쓰도록 설정했다.
그러나 실제로 executor별로 할당된 코어수는 1개 뿐이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/22/2020-09-22-yarn-cores-before.jpeg&quot; alt=&quot;yarn-cores-before&quot; /&gt;&lt;/p&gt;

&lt;p&gt;코어가 설정값대로 할당되지 않는 이유는 YARN의 디폴트 스케줄러 설정이 CPU 스케줄링을 지원하지 않기 때문이다.
YARN의 스케줄링과 리소스 할당을 간단하게 살펴보자.&lt;/p&gt;

&lt;h2 id=&quot;2-yarn-스케줄링&quot;&gt;2. YARN 스케줄링&lt;/h2&gt;
&lt;p&gt;YARN은 애플리케이션의 요청에 따라 클러스터의 자원을 할당해주어야 한다.
이러한 역할은 YARN 스케줄러가 수행한다.
YARN은 다음 이미지와 같이 3가지 스케줄러 옵션을 제공한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/22/2020-09-22-yarn-scheduling.png&quot; alt=&quot;yarn_scheduling&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-1-fifo-scheduler&quot;&gt;2-1. FIFO Scheduler&lt;/h3&gt;
&lt;p&gt;모든 잡은 큐에 들어운 순서대로 실행되고 자기 차례가 될 때까지 대기해야 한다.
간단하고 이해하기 쉽지만 하나의 잡이 모든 자원을 차지해버릴 수 있기 때문에 
대규모 클러스터에서 사용하기에 적합하진 않다.&lt;/p&gt;

&lt;h3 id=&quot;2-2-capacity-scheduler&quot;&gt;2-2. Capacity Scheduler&lt;/h3&gt;
&lt;p&gt;각각의 잡은 서로 구분되는 전용 큐에서 처리된다.
잡을 위한 자원을 미리 예약해두어야 하므로 전체 클러스터 관점에선 자원 효율성이 떨어진다.
보통 이 capacity scheduler를 기본적으로 사용하게 된다.&lt;/p&gt;

&lt;h3 id=&quot;2-3-fair-scheduler&quot;&gt;2-3. Fair Scheduler&lt;/h3&gt;
&lt;p&gt;실행 중인 모든 잡에 대해 자원을 동적으로 할당해준다.
이미 잡이 실행 중일 때 다른 잡이 추가되면 각 잡은 클러스터 자원을 절반씩 할당받는다.
즉, 잡들이 공평하게 자원을 나눠가질 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;3-yarn-resource-allocation&quot;&gt;3. YARN Resource Allocation&lt;/h2&gt;
&lt;h3 id=&quot;3-1-default-resource-calculator&quot;&gt;3-1. Default Resource Calculator&lt;/h3&gt;
&lt;p&gt;언급한대로 Capacity Scheduler를 디폴트로 사용한다.
스케줄링의 기본 단위는 큐이며 각 잡은 전용 큐에서 처리된다.
각 큐의 용량은 클러스터 가용 자원 중 애플리케이션이 제출한 비율만큼을 할당하여 정해진다.&lt;/p&gt;

&lt;p&gt;이 과정에서 클러스터 자원 할당을 위해 Resource Calculator가 사용된다.
YARN이 디폴트로 사용하는 것은 &lt;strong&gt;DefaultResourceCalculator&lt;/strong&gt;이다.
DefaultResourceCalculator는 오직 메모리만을 기준으로 하여 자원을 할당한다.
즉, CPU 코어 수는 스케줄링하지 않는다.
처음 Hadoop 클러스터를 구성했을 때 YARN 애플리케이션에 CPU 코어 수를 원하는대로 할당할 수 없는 이유가 바로 이것이다.&lt;/p&gt;

&lt;h3 id=&quot;3-2-dominant-resource-calculator&quot;&gt;3-2. Dominant Resource Calculator&lt;/h3&gt;
&lt;p&gt;CPU 자원을 할당하는 방법은 Resource Calculator를 &lt;strong&gt;DominantResourceCalculator&lt;/strong&gt;로 변경하는 것이다.
YARN의 ResourceManager와 각 NodeManager에서 Hadoop 설정 파일 중 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;capacity-scheduler.xml&lt;/code&gt;를 열어보자.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# vim /etc/hadoop/conf/capacity-scheduler.xml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여러 property들 중에서 resource-calaulator 항목을 찾을 수 있다.
최초 설치 시 DefaultResourceCalculator로 설정되어 있는데 이를 다음처럼 DominantResourceCalculator로 변경하면 된다.&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.scheduler.capacity.resource-calculator&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;org.apache.hadoop.yarn.util.resource.DominantResourceCalculator&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-3-hdp의-resource-calculator-수정하기&quot;&gt;3-3. HDP의 Resource Calculator 수정하기&lt;/h3&gt;

&lt;p&gt;HDP의 경우엔 Ambari에서 CPU Scheduling 설정을 Enabled로 변경하면 모든 YARN 컴포넌트 서버들에 대해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;capacity-scheduler.xml&lt;/code&gt;가 일괄적을 수정된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/22/2020-09-22-yarn-cpu-scheduling-config.jpeg&quot; alt=&quot;yarn_cpu_scheduling_config&quot; /&gt;&lt;/p&gt;

&lt;p&gt;맨 처음 실행했던 pyspark 코드를 다시 실행하면 아래와 같이 설정대로 executor별 코어가 할당되는 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/22/2020-09-22-yarn-cores-after.jpeg&quot; alt=&quot;yarn-cores-after&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;https://towardsdatascience.com/schedulers-in-yarn-concepts-to-configurations-5dd7ced6c214&lt;/li&gt;
  &lt;li&gt;https://docs.cloudera.com/HDPDocuments/HDP2/HDP-2.6.3/bk_yarn-resource-management/content/about_yarn_resource_allocation.html&lt;/li&gt;
  &lt;li&gt;“하둡 완벽 가이드 (4판)”, 한빛미디어, 톰 화이트 지음&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="apache-hadoop" /><category term="yarn" /><category term="spark" /><summary type="html">1. YARN의 초기 CPU 스케줄링 문제 Hadoop 클러스터를 처음 구축하면 애플리케이션을 제출할 때 CPU 코어 수가 원하는대로 할당되지 않는 문제를 겪게 된다. 아래와 같이 yarn-client 모드로 SparkSession을 생성하는 예시를 보자.</summary></entry><entry><title type="html">오픈 소스 bug-fix에 기여한 소소한 썰</title><link href="http://localhost:4000/apache-nutch/opensource-bugfix-ssul/" rel="alternate" type="text/html" title="오픈 소스 bug-fix에 기여한 소소한 썰" /><published>2020-09-16T00:00:00+09:00</published><updated>2020-09-16T00:00:00+09:00</updated><id>http://localhost:4000/apache-nutch/opensource-bugfix-ssul</id><content type="html" xml:base="http://localhost:4000/apache-nutch/opensource-bugfix-ssul/">&lt;p&gt;최근 웹 크롤러를 구축하기 위해 Apache Nutch를 사용하다가 소스코드 상의 버그를 발견하게 되었다.
이를 해결하고 contributor에게 공유했던 경험을 기록해보았다.&lt;/p&gt;

&lt;h2 id=&quot;1-문제의-발견&quot;&gt;1. 문제의 발견&lt;/h2&gt;
&lt;h3 id=&quot;1-1-nutch-workflow&quot;&gt;1-1. Nutch Workflow&lt;/h3&gt;
&lt;p&gt;Apache Nutch는 Hadoop 위에서 동작하는 분산형 웹 크롤러다.
(&lt;a href=&quot;https://dhkdn9192.github.io/apache-nutch/nutch-tuning/&quot;&gt;이전 포스트&lt;/a&gt;)
웹 페이지를 수집하기 위한 다양한 컴포넌트들로 구성되며 아래와 같은 워크플로우로 동작한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/16/2020-09-16-nutch-overall-workflow.png&quot; alt=&quot;nutch_workflow&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;워크플로우에서 웹 페이지의 수집은 (3)&lt;strong&gt;Fetcher&lt;/strong&gt;에 의해 이뤄진다.&lt;/li&gt;
  &lt;li&gt;Fetcher는 수집할 url 목록(fetchlist)을 입력받아 동작하며 이 목록은 (2)&lt;strong&gt;Generator&lt;/strong&gt;가 생성한다.&lt;/li&gt;
  &lt;li&gt;Generator는 url 메타정보를 가지고 있는 &lt;strong&gt;crawldb&lt;/strong&gt;를 참조하여 수집한 적이 없는 url들로 목록을 구성한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;즉 Nutch가 어느 url들을 수집할 것인지는 Generator에 의해서 결정된다.
Generator는 
&lt;em&gt;사용자가 특정 url들을 추가하거나 외부로부터 데이터를 입력받아 목록을 생성할 수가 없다&lt;/em&gt;.
(regex-urlfilter나 blacklist 등의 기능으로 필터링하는 것은 가능하다)&lt;/p&gt;

&lt;h3 id=&quot;1-2-freegenerator&quot;&gt;1-2. FreeGenerator&lt;/h3&gt;
&lt;p&gt;이러한 불편함을 해소하기 위해 Nutch는 사용자가 직접 url 목록을 입력할 수 있도록 &lt;strong&gt;FreeGenerator&lt;/strong&gt;라는 클래스를 제공하고 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ bin/nutch freegen --help
Usage: FreeGenerator &amp;lt;inputDir&amp;gt; &amp;lt;segmentsDir&amp;gt; [-filter] [-normalize] [-numFetchers &amp;lt;n&amp;gt;]
        inputDir        input directory containing one or more input files.
                        Each text file contains a list of URLs, one URL per line
        segmentsDir     output directory, where new segment will be created
        -filter         run current URLFilters on input URLs
        -normalize      run current URLNormalizers on input URLs
        -numFetchers &amp;lt;n&amp;gt;        number of generated fetch lists, determines number of fetcher tasks
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bin/nutch freegen&lt;/code&gt; 명령어로 동작하며 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;inputDir&amp;gt;&lt;/code&gt; 옵션에 디렉토리 경로를 명시해주면
해당 경로의 텍스트 파일들을 읽어 url 목록을 생성한다.
즉, 내가 수집하고 싶은 url들로 목록을 생성할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;2-무엇이-원인이었나&quot;&gt;2. 무엇이 원인이었나?&lt;/h2&gt;

&lt;h2 id=&quot;3-고치기&quot;&gt;3. 고치기&lt;/h2&gt;

&lt;h2 id=&quot;4-공유하기&quot;&gt;4. 공유하기&lt;/h2&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;https://florianhartl.com/nutch-how-it-works.html&lt;/li&gt;
  &lt;li&gt;https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=122916819&lt;/li&gt;
  &lt;li&gt;https://github.com/apache/nutch/pull/519&lt;/li&gt;
  &lt;li&gt;https://issues.apache.org/jira/browse/NUTCH-2810&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="apache-nutch" /><category term="java" /><category term="nutch" /><category term="jira" /><summary type="html">최근 웹 크롤러를 구축하기 위해 Apache Nutch를 사용하다가 소스코드 상의 버그를 발견하게 되었다. 이를 해결하고 contributor에게 공유했던 경험을 기록해보았다.</summary></entry></feed>