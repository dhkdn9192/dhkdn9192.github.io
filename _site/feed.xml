<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-05-25T22:28:01+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">오류동 개발자</title><subtitle>개발과 일상적인 이야기들</subtitle><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><entry><title type="html">Spark Executor의 메모리 구조</title><link href="http://localhost:4000/apache-spark/spark_executor_memory_structure/" rel="alternate" type="text/html" title="Spark Executor의 메모리 구조" /><published>2021-05-25T00:00:00+09:00</published><updated>2021-05-25T00:00:00+09:00</updated><id>http://localhost:4000/apache-spark/spark_executor_memory_structure</id><content type="html" xml:base="http://localhost:4000/apache-spark/spark_executor_memory_structure/">&lt;p&gt;Spark 1.6 이상부턴 메모리 관리가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UnifiedMemoryManager&lt;/code&gt; class에 의해 이뤄진다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/data_engineer_should_know/master/interview/hadoop/img/spark_executor_memory_distribution.png&quot; alt=&quot;executor_memory_distribution&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-reserved-memory&quot;&gt;1. Reserved Memory&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;시스템에 의해 관리되는 메모리 영역으로 크기가 300MB로 고정되어 있다.&lt;/li&gt;
  &lt;li&gt;Spark의 internal object들이 저장된다.&lt;/li&gt;
  &lt;li&gt;Executor에 할당해준 메모리가 Reserved Memory 크기의 1.5배 미만이면 “&lt;em&gt;please use larger heap size&lt;/em&gt;“라는 문구와 함께 에러가 발생한다.&lt;/li&gt;
  &lt;li&gt;메모리 사이즈 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;300 MB (고정)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-user-memory&quot;&gt;2. User Memory&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;사용자가 정의한 데이터구조, UDF가 저장되는 공간이다.&lt;/li&gt;
  &lt;li&gt;Spark에 의해 관리되지 않으며 Spark은 User Memory 공간을 인지하지 않는다.&lt;/li&gt;
  &lt;li&gt;Java Heap 메모리에서 Reserved Memory를 제외한 공간 중에서 Spark Memory 가 아닌 나머지 부분이다.&lt;/li&gt;
  &lt;li&gt;메모리 사이즈 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(Java Heap Memory - Reserved Memory) * (1 - spark.memory.fraction)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-spark-memory&quot;&gt;3. Spark Memory&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Spark에 의해 관리되는 메모리 영역이다.&lt;/li&gt;
  &lt;li&gt;join과 같은 연산들이 실행되는 동안의 내부 상태가 저장되거나 broadcast 변수 등이 저장되는 영역이다.&lt;/li&gt;
  &lt;li&gt;cache/persist에 의해 캐싱된 데이터가 저장되는 영역이다.&lt;/li&gt;
  &lt;li&gt;Storage Memory 영역과 Execution Memory의 두 영역으로 나뉜다.&lt;/li&gt;
  &lt;li&gt;메모리 사이즈 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(Java Heap Memory - Reserved Memory) * spark.memory.fraction&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-1-storage-memory&quot;&gt;3-1. Storage Memory&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;cache된 데이터, broadcast 변수가 저장된다.&lt;/li&gt;
  &lt;li&gt;persist 옵션이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MEMORY&lt;/code&gt;이면 이 영역에 데이터가 캐싱된다.&lt;/li&gt;
  &lt;li&gt;캐싱할 공간이 부족하여 오래된 캐시 데이터를 지울 경우엔 &lt;strong&gt;LRU(Least Recently Used) 방식으로 제거&lt;/strong&gt;한다. (즉, 블록이 디스크로 강제 추방될 수 있다.)&lt;/li&gt;
  &lt;li&gt;캐싱된 데이터가 메모리에서 벗어날 경우에는 디스크에 저장되거나 새로 계산되어야 한다.&lt;/li&gt;
  &lt;li&gt;메모리 사이즈 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(Java Heap Memory - Reserved Memory) * spark.memory.fraction * spark.memory.storageFraction&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-2-execution-memory&quot;&gt;3-2. Execution Memory&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Spark이 task를 실행(execute)하는 동안 생성되는 object 들이 저장된다.&lt;/li&gt;
  &lt;li&gt;예시) Hash aggregation step에서 해쉬 테이블을 저장하거나, Map 수행 시 Shuffle intermediate buffer를 저장한다.&lt;/li&gt;
  &lt;li&gt;메모리가 충분하지 않을 경우, 디스크로의 spilling을 지원한다.&lt;/li&gt;
  &lt;li&gt;단, 이 영역의 블록은 다른 task에 의해 강제로 추방될 수는 없다. (Storage Memory와 다른 점)&lt;/li&gt;
  &lt;li&gt;메모리 사이즈 : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(Java Heap Memory - Reserved Memory) * spark.memory.fraction * (1 - spark.memory.storageFraction)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-3-storage-memory-vs-execution-memory-비교&quot;&gt;3-3. Storage Memory vs Execution Memory 비교&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Storage Memory는 Execution Memory가 사용되지 않는 경우에만 Execution Memory 영역을 빌릴 수 있다.&lt;/li&gt;
  &lt;li&gt;Execution Memory 역시 Storage Memory가 사용되지 않을 경우 Storage Memory 영역을 빌릴 수 있다.&lt;/li&gt;
  &lt;li&gt;Storage Memory가 점유한 Execution Memory 블록은 Execution이 요청할 경우, &lt;strong&gt;강제로 추방될 수 있다&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Execution Memory가 점유한 Storage Memory 블록은 Storage가 요청하더라도, &lt;strong&gt;강제로 추방될 수 없다&lt;/strong&gt;. (Spark이 Execution의 블록을 release할 때까지 기다려야 한다.)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;em&gt;즉, 블록 추방 우선도는 Storage Memory &amp;lt; Execution Memory라 할 수 있다.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-executor-메모리-할당-예시&quot;&gt;4. Executor 메모리 할당 예시&lt;/h2&gt;

&lt;p&gt;Executor 메모리 설정이 다음 표와 같을 경우, 각 메모리 영역에 할당되는 실제 사이즈 계산&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;conf&lt;/th&gt;
      &lt;th&gt;value&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.executor.memory&lt;/td&gt;
      &lt;td&gt;4g&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.memory.fraction&lt;/td&gt;
      &lt;td&gt;0.75&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.memory.storageFraction&lt;/td&gt;
      &lt;td&gt;0.5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;Reserved Memory : &lt;strong&gt;300MB&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;User Memory : (4096MB - 300MB) * (1 - 0.75) = &lt;strong&gt;949MB&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Spark Memory : (4096MB - 300MB) * 0.75 = &lt;strong&gt;2847MB&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Storage Memory : (4096MB - 300MB) * 0.75 * 0.5 = &lt;strong&gt;1423MB&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Execution Memory : (4096MB - 300MB) * 0.75 * (1 - 0.5) = &lt;strong&gt;1423MB&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;https://medium.com/analytics-vidhya/apache-spark-memory-management-49682ded3d42&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="apache-spark" /><category term="spark" /><category term="java" /><category term="jvm" /><summary type="html">Spark 1.6 이상부턴 메모리 관리가 UnifiedMemoryManager class에 의해 이뤄진다.</summary></entry><entry><title type="html">[YARN] CPU 코어 할당을 위한 스케줄러 설정</title><link href="http://localhost:4000/apache-hadoop/yarn-resource-allocation/" rel="alternate" type="text/html" title="[YARN] CPU 코어 할당을 위한 스케줄러 설정" /><published>2020-09-22T00:00:00+09:00</published><updated>2020-09-22T00:00:00+09:00</updated><id>http://localhost:4000/apache-hadoop/yarn-resource-allocation</id><content type="html" xml:base="http://localhost:4000/apache-hadoop/yarn-resource-allocation/">&lt;h2 id=&quot;1-yarn의-초기-cpu-스케줄링-문제&quot;&gt;1. YARN의 초기 CPU 스케줄링 문제&lt;/h2&gt;
&lt;p&gt;Hadoop 클러스터를 처음 구축하면 애플리케이션을 제출할 때 CPU 코어 수가 원하는대로 할당되지 않는 문제를 겪게 된다.
아래와 같이 yarn-client 모드로 SparkSession을 생성하는 예시를 보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SparkSession&lt;/span&gt; \
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;builder&lt;/span&gt; \
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;appName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Spark_Example&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;master&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;yarn-client&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark.executor.instances&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark.executor.memory&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;10g&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark.executor.cores&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;5&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getOrCreate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.executor.cores&lt;/code&gt; 설정으로 executor 당 5개 코어를 쓰도록 설정했다.
그러나 실제로 executor별로 할당된 코어수는 1개 뿐이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/22/2020-09-22-yarn-cores-before.jpeg&quot; alt=&quot;yarn-cores-before&quot; /&gt;&lt;/p&gt;

&lt;p&gt;코어가 설정값대로 할당되지 않는 이유는 YARN의 디폴트 스케줄러 설정이 CPU 스케줄링을 지원하지 않기 때문이다.
YARN의 스케줄링과 리소스 할당을 간단하게 살펴보자.&lt;/p&gt;

&lt;h2 id=&quot;2-yarn-스케줄링&quot;&gt;2. YARN 스케줄링&lt;/h2&gt;
&lt;p&gt;YARN은 애플리케이션의 요청에 따라 클러스터의 자원을 할당해주어야 한다.
이러한 역할은 YARN 스케줄러가 수행한다.
YARN은 다음 이미지와 같이 3가지 스케줄러 옵션을 제공한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/22/2020-09-22-yarn-scheduling.png&quot; alt=&quot;yarn_scheduling&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-1-fifo-scheduler&quot;&gt;2-1. FIFO Scheduler&lt;/h3&gt;
&lt;p&gt;모든 잡은 큐에 들어운 순서대로 실행되고 자기 차례가 될 때까지 대기해야 한다.
간단하고 이해하기 쉽지만 하나의 잡이 모든 자원을 차지해버릴 수 있기 때문에 
대규모 클러스터에서 사용하기에 적합하진 않다.&lt;/p&gt;

&lt;h3 id=&quot;2-2-capacity-scheduler&quot;&gt;2-2. Capacity Scheduler&lt;/h3&gt;
&lt;p&gt;각각의 잡은 서로 구분되는 전용 큐에서 처리된다.
잡을 위한 자원을 미리 예약해두어야 하므로 전체 클러스터 관점에선 자원 효율성이 떨어진다.
보통 이 capacity scheduler를 기본적으로 사용하게 된다.&lt;/p&gt;

&lt;h3 id=&quot;2-3-fair-scheduler&quot;&gt;2-3. Fair Scheduler&lt;/h3&gt;
&lt;p&gt;실행 중인 모든 잡에 대해 자원을 동적으로 할당해준다.
이미 잡이 실행 중일 때 다른 잡이 추가되면 각 잡은 클러스터 자원을 절반씩 할당받는다.
즉, 잡들이 공평하게 자원을 나눠가질 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;3-yarn-resource-allocation&quot;&gt;3. YARN Resource Allocation&lt;/h2&gt;
&lt;h3 id=&quot;3-1-default-resource-calculator&quot;&gt;3-1. Default Resource Calculator&lt;/h3&gt;
&lt;p&gt;언급한대로 Capacity Scheduler를 디폴트로 사용한다.
스케줄링의 기본 단위는 큐이며 각 잡은 전용 큐에서 처리된다.
각 큐의 용량은 클러스터 가용 자원 중 애플리케이션이 제출한 비율만큼을 할당하여 정해진다.&lt;/p&gt;

&lt;p&gt;이 과정에서 클러스터 자원 할당을 위해 Resource Calculator가 사용된다.
YARN이 디폴트로 사용하는 것은 &lt;strong&gt;DefaultResourceCalculator&lt;/strong&gt;이다.
DefaultResourceCalculator는 오직 메모리만을 기준으로 하여 자원을 할당한다.
즉, CPU 코어 수는 스케줄링하지 않는다.
처음 Hadoop 클러스터를 구성했을 때 YARN 애플리케이션에 CPU 코어 수를 원하는대로 할당할 수 없는 이유가 바로 이것이다.&lt;/p&gt;

&lt;h3 id=&quot;3-2-dominant-resource-calculator&quot;&gt;3-2. Dominant Resource Calculator&lt;/h3&gt;
&lt;p&gt;CPU 자원을 할당하는 방법은 Resource Calculator를 &lt;strong&gt;DominantResourceCalculator&lt;/strong&gt;로 변경하는 것이다.
YARN의 ResourceManager와 각 NodeManager에서 Hadoop 설정 파일 중 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;capacity-scheduler.xml&lt;/code&gt;를 열어보자.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# vim /etc/hadoop/conf/capacity-scheduler.xml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여러 property들 중에서 resource-calaulator 항목을 찾을 수 있다.
최초 설치 시 DefaultResourceCalculator로 설정되어 있는데 이를 다음처럼 DominantResourceCalculator로 변경하면 된다.&lt;/p&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.scheduler.capacity.resource-calculator&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;org.apache.hadoop.yarn.util.resource.DominantResourceCalculator&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-3-hdp의-resource-calculator-수정하기&quot;&gt;3-3. HDP의 Resource Calculator 수정하기&lt;/h3&gt;

&lt;p&gt;HDP의 경우엔 Ambari에서 CPU Scheduling 설정을 Enabled로 변경하면 모든 YARN 컴포넌트 서버들에 대해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;capacity-scheduler.xml&lt;/code&gt;가 일괄적을 수정된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/22/2020-09-22-yarn-cpu-scheduling-config.jpeg&quot; alt=&quot;yarn_cpu_scheduling_config&quot; /&gt;&lt;/p&gt;

&lt;p&gt;맨 처음 실행했던 pyspark 코드를 다시 실행하면 아래와 같이 설정대로 executor별 코어가 할당되는 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/22/2020-09-22-yarn-cores-after.jpeg&quot; alt=&quot;yarn-cores-after&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;https://towardsdatascience.com/schedulers-in-yarn-concepts-to-configurations-5dd7ced6c214&lt;/li&gt;
  &lt;li&gt;https://docs.cloudera.com/HDPDocuments/HDP2/HDP-2.6.3/bk_yarn-resource-management/content/about_yarn_resource_allocation.html&lt;/li&gt;
  &lt;li&gt;“하둡 완벽 가이드 (4판)”, 한빛미디어, 톰 화이트 지음&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="apache-hadoop" /><category term="yarn" /><category term="spark" /><summary type="html">1. YARN의 초기 CPU 스케줄링 문제 Hadoop 클러스터를 처음 구축하면 애플리케이션을 제출할 때 CPU 코어 수가 원하는대로 할당되지 않는 문제를 겪게 된다. 아래와 같이 yarn-client 모드로 SparkSession을 생성하는 예시를 보자.</summary></entry><entry><title type="html">오픈 소스 bug-fix에 기여한 소소한 썰</title><link href="http://localhost:4000/apache-nutch/opensource-bugfix-ssul/" rel="alternate" type="text/html" title="오픈 소스 bug-fix에 기여한 소소한 썰" /><published>2020-09-16T00:00:00+09:00</published><updated>2020-09-16T00:00:00+09:00</updated><id>http://localhost:4000/apache-nutch/opensource-bugfix-ssul</id><content type="html" xml:base="http://localhost:4000/apache-nutch/opensource-bugfix-ssul/">&lt;p&gt;최근 웹 크롤러를 구축하기 위해 Apache Nutch를 사용하다가 소스코드 상의 버그를 발견하게 되었다.
이를 해결하고 contributor에게 공유했던 경험을 기록해보았다.&lt;/p&gt;

&lt;h2 id=&quot;1-문제의-발견&quot;&gt;1. 문제의 발견&lt;/h2&gt;
&lt;h3 id=&quot;1-1-nutch-workflow&quot;&gt;1-1. Nutch Workflow&lt;/h3&gt;
&lt;p&gt;Apache Nutch는 Hadoop 위에서 동작하는 분산형 웹 크롤러다.
(&lt;a href=&quot;https://dhkdn9192.github.io/apache-nutch/nutch-tuning/&quot;&gt;이전 포스트&lt;/a&gt;)
웹 페이지를 수집하기 위한 다양한 컴포넌트들로 구성되며 아래와 같은 워크플로우로 동작한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/16/2020-09-16-nutch-overall-workflow.png&quot; alt=&quot;nutch_workflow&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;워크플로우에서 웹 페이지의 수집은 (3)&lt;strong&gt;Fetcher&lt;/strong&gt;에 의해 이뤄진다.&lt;/li&gt;
  &lt;li&gt;Fetcher는 수집할 url 목록(fetchlist)을 입력받아 동작하며 이 목록은 (2)&lt;strong&gt;Generator&lt;/strong&gt;가 생성한다.&lt;/li&gt;
  &lt;li&gt;Generator는 url 메타정보를 가지고 있는 &lt;strong&gt;crawldb&lt;/strong&gt;를 참조하여 수집한 적이 없는 url들로 목록을 구성한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;즉 Nutch가 어느 url들을 수집할 것인지는 Generator에 의해서 결정된다.
Generator는 
&lt;em&gt;사용자가 특정 url들을 추가하거나 외부로부터 데이터를 입력받아 목록을 생성할 수가 없다&lt;/em&gt;.
(regex-urlfilter나 blacklist 등의 기능으로 필터링하는 것은 가능하다)&lt;/p&gt;

&lt;h3 id=&quot;1-2-freegenerator&quot;&gt;1-2. FreeGenerator&lt;/h3&gt;
&lt;p&gt;이러한 불편함을 해소하기 위해 Nutch는 사용자가 직접 url 목록을 입력할 수 있도록 &lt;strong&gt;FreeGenerator&lt;/strong&gt;라는 클래스를 제공하고 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ bin/nutch freegen --help
Usage: FreeGenerator &amp;lt;inputDir&amp;gt; &amp;lt;segmentsDir&amp;gt; [-filter] [-normalize] [-numFetchers &amp;lt;n&amp;gt;]
        inputDir        input directory containing one or more input files.
                        Each text file contains a list of URLs, one URL per line
        segmentsDir     output directory, where new segment will be created
        -filter         run current URLFilters on input URLs
        -normalize      run current URLNormalizers on input URLs
        -numFetchers &amp;lt;n&amp;gt;        number of generated fetch lists, determines number of fetcher tasks
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bin/nutch freegen&lt;/code&gt; 명령어로 동작하며 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;inputDir&amp;gt;&lt;/code&gt; 옵션에 디렉토리 경로를 명시해주면
해당 경로의 텍스트 파일들을 읽어 url 목록을 생성한다.
즉, 내가 수집하고 싶은 url들로 목록을 생성할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;2-무엇이-원인이었나&quot;&gt;2. 무엇이 원인이었나?&lt;/h2&gt;

&lt;h2 id=&quot;3-고치기&quot;&gt;3. 고치기&lt;/h2&gt;

&lt;h2 id=&quot;4-공유하기&quot;&gt;4. 공유하기&lt;/h2&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;https://florianhartl.com/nutch-how-it-works.html&lt;/li&gt;
  &lt;li&gt;https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=122916819&lt;/li&gt;
  &lt;li&gt;https://github.com/apache/nutch/pull/519&lt;/li&gt;
  &lt;li&gt;https://issues.apache.org/jira/browse/NUTCH-2810&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="apache-nutch" /><category term="java" /><category term="nutch" /><category term="jira" /><summary type="html">최근 웹 크롤러를 구축하기 위해 Apache Nutch를 사용하다가 소스코드 상의 버그를 발견하게 되었다. 이를 해결하고 contributor에게 공유했던 경험을 기록해보았다.</summary></entry><entry><title type="html">Apache Nutch 튜닝하기</title><link href="http://localhost:4000/apache-nutch/nutch-tuning/" rel="alternate" type="text/html" title="Apache Nutch 튜닝하기" /><published>2020-09-14T00:00:00+09:00</published><updated>2020-09-14T00:00:00+09:00</updated><id>http://localhost:4000/apache-nutch/nutch-tuning</id><content type="html" xml:base="http://localhost:4000/apache-nutch/nutch-tuning/">&lt;h2 id=&quot;1-apache-nutch&quot;&gt;1. Apache Nutch&lt;/h2&gt;
&lt;p&gt;Apache Nutch는 Java 언어로 만들어진 분산형 웹 크롤러다.
현재는 널리 쓰이고 있는 Hadoop이 바로 이 Nutch의 하위 프로젝트에서 시작되었다.
최근 Nutch로 웹 크롤러를 구축하면서 소소하게 경험해본 것들을 기록해본다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/14/2020-09-14-nutch-logo.png&quot; alt=&quot;nutch-logo&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;version&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Nutch&lt;/td&gt;
      &lt;td&gt;1.17&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;OpenJDK&lt;/td&gt;
      &lt;td&gt;1.8.0_265&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Hadoop&lt;/td&gt;
      &lt;td&gt;2.7.3 (hdp 2.6.3)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;2-what-to-crawl&quot;&gt;2. What to crawl&lt;/h2&gt;
&lt;p&gt;구축할 웹 크롤러의 목적은 타겟 해외 사이트들을 주기적으로 수집하는 것이다.
주식 관련 뉴스들을 제공해주는 소스 사이트들이 존재하는데,
이들 사이트를 seed로 하여 페이지 내의 뉴스 링크들을 수집하는 것이다.&lt;/p&gt;

&lt;p&gt;Nutch는 방대한 인터넷 세계를 깊이 탐색하며 수집할 수 있도록 설계된 범용성 있는 크롤러다.
때문에 내 요구사항에 그대로 맞춰 사용하기에는 어려운 점들이 많아 일부 튜닝이 필요했다.&lt;/p&gt;

&lt;h2 id=&quot;3-tuning&quot;&gt;3. Tuning&lt;/h2&gt;
&lt;h3 id=&quot;3-1-이전-페이지의-url-저장하기&quot;&gt;3-1. 이전 페이지의 url 저장하기&lt;/h3&gt;
&lt;p&gt;Nutch는 웹 페이지를 저장(indexing)할 때 해당 페이지로 연결되는 &lt;strong&gt;이전 페이지의 링크 텍스트&lt;/strong&gt;(anchor)를 함께 기록한다.
아래처럼 뉴스 타이틀에 하이퍼링크가 걸려있어서 뉴스 페이지로 연결될 경우, anchor 필드에 뉴스 타이틀이 들어오게 된다.
혹은 “다음 기사”와 같이 버튼을 눌러 뉴스 페이지로 연결될 수도 있다.&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;tstamp&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2020-06-30T01:58:26.987Z&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;anchor&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
	&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Facebook Sales at Risk as Starbucks Bails&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
	&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Next Article&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
	&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;title&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Facebook Sales at Risk as Starbucks Bails&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;url&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
	&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여기서 내가 수집하고 싶은 정보는 링크 텍스트가 아니라 &lt;strong&gt;이전 페이지의 url&lt;/strong&gt;이다.
즉 아래처럼 anchor 필드에는 현재 페이지로 연결되는 url들이 들어와야 한다.&lt;/p&gt;
&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;tstamp&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2020-06-30T01:58:26.987Z&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;anchor&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
	&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://first.link.url/quote.ashx?q=facebook&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
	&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://second.link.url/quote.ashx?q=facebook&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
	&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;title&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Facebook Sales at Risk as Starbucks Bails&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;url&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
	&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위처럼 이전페이지 url을 넣는 방법은 간단하다.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;src/java/org/apache/nutch/crawl/Inlinks.java&lt;/code&gt; 코드에서 
Inlinks 클래스의 getAnchors 메소드를 수정해주면 된다.
while문의 마지막 if문에서 anchor 대신 fromUrl을 results에 입력해준다.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getAnchors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;HashMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;domainToAnchors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HashMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Inlink&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inlinks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hasNext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;Inlink&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inlink&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anchor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inlink&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getAnchor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fromUrl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inlink&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getFromUrl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;

      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;anchor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// skip empty anchors&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;domain&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// extract domain name&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;domain&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;URL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromUrl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getHost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MalformedURLException&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;Set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;domainAnchors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;domainToAnchors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;domain&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;domainAnchors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;domainAnchors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HashSet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;domainToAnchors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;domain&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;domainAnchors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;domainAnchors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromUrl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromUrl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// 이전 페이지의 url 입력&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;toArray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()]);&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;소스코드 수정 후 Nutch를 다시 빌드해준다.
이제부턴 anchor 필드에 이전 페이지 url이 입력될 것이다.&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ant runtime
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-2-원본-html-저장하기&quot;&gt;3-2. 원본 html 저장하기&lt;/h3&gt;
&lt;p&gt;Nutch는 자체 parser로 html의 텍스트를 추출/파싱해준다.
하지만 파싱되지 않은 원본 그대로의 html을 저장하고 싶을 경우,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-addBinaryContent&lt;/code&gt; 옵션을 사용하면 된다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;nutch index &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;crawldb 경로&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-linkdb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;linkdb 경로&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;대상 segment 경로&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-filter&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-normalize&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-deleteGone&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-addBinaryContent&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-base64&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;인코딩 문제를 방지하기 위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-base64&lt;/code&gt; 인코딩 옵션을 함께 사용하는 것이 좋다.
주의할 점은, 1.15 버전에선 버그로 인하여 해당 옵션을 사용할 경우 에러가 발생하게 된다는 것이다.
이 버그는 1.16 버전부터는 개선되었으며 최신 버전을 사용한다면 문제 없다.
자세한 사항은 &lt;a href=&quot;https://issues.apache.org/jira/browse/NUTCH-2706&quot;&gt;NUTCH-2706&lt;/a&gt; 이슈를 참고&lt;/p&gt;

&lt;h3 id=&quot;3-3-batch-수행간-중복-url-제거&quot;&gt;3-3. batch 수행간 중복 url 제거&lt;/h3&gt;
&lt;p&gt;Nutch는 실행되는 동안 한 번이라도 수집된 페이지는 다시 수집하지 않는다.
timeout을 설정하면 수집된 페이지도 일정 시간 뒤 재수집이 가능하지만 특정 페이지만 재수집하는 것은 불가능하다.&lt;/p&gt;

&lt;p&gt;나의 개발요건은 seed url들을 주기적으로 반복 수집하며 신규 페이지들을 수집하는 것이다.
그러나 Nutch의 특성상 seed url들만 재수집할 수는 없으므로,
매번 crawldb를 리셋시키고 처음부터 crawling을 수행해야 했다.&lt;/p&gt;

&lt;p&gt;그 결과, 매번 crawldb가 리셋되므로 각 Nutch 배치잡은 이전 배치에서 수집했던 페이지들을 중복으로 수집했다.
Nutch가 페이지를 저장하는 과정에서 중복 페이지는 알아서 제거되지만,
문제는 불필요한 중복 페이지 수집 때문에 fetch time이 너무 오래걸린다는 것이다.
(Nutch는 politeness를 최대한 준수하기 위해 동일 서버에 대해 기본적으로 5초의 idle time을 갖는다.)&lt;/p&gt;

&lt;p&gt;아래는 Nutch의 워크플로우 구조다.
&lt;strong&gt;inject&lt;/strong&gt; &amp;gt; [ &lt;strong&gt;generate&lt;/strong&gt; &amp;gt; &lt;strong&gt;fetch&lt;/strong&gt; &amp;gt; &lt;strong&gt;parse&lt;/strong&gt; &amp;gt; &lt;strong&gt;update&lt;/strong&gt; ]*n &amp;gt; &lt;strong&gt;invert links&lt;/strong&gt; &amp;gt; &lt;strong&gt;index&lt;/strong&gt; 순서로 작업이 진행된다.
&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/14/2020-09-14-nutch-workflow.png&quot; alt=&quot;nutch-workflow&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;inject&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;- 수집의 시작점이 되는 seed url들을 crawldb에 입력한다&lt;br /&gt;- crawldb는 url들의 메타정보들을 저장한 DB이다&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;generate&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;- crawldb로부터 수집할 url 목록인 fetchlist를 생성한다.&lt;br /&gt;- fetchlist는 아직 수집하지 않은 url들로 구성된다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;fetch&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;- 앞서 작성된 fetchlist의 url들에 대해 실제로 수집을 수행한다.&lt;br /&gt;- 각 url들의 컨텐츠(html)를 가져온다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;parse&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;- 수집된 컨텐츠를 파싱한다.&lt;br /&gt;- 웹 페이지의 텍스트, html 속 href 태그들, 날짜/시간 정보 등을 추출한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;update&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;- 파싱 단계에서 새로 얻어진 url들을 crawldb에 추가한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;invert links&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;- 페이지간의 연결 정보를 linkdb에 갱신한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;index&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;-크롤링된 웹 페이지들을 Solr, Elasticsearch, Kafka 등에 인덱싱한다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;여기서 각 Nutch 배치가 이전 배치의 수집 url들을 제거하여 fetch list를 줄일 수 있도록 워크플로우를 수정했다.
 &lt;strong&gt;generate&lt;/strong&gt; ~ &lt;strong&gt;update&lt;/strong&gt;  의 사이클을 1회만 수행한다.
그 후, 갱신된 crawldb를 읽어(&lt;strong&gt;readdb&lt;/strong&gt;) 이전 배치에서 수집한 url들을 제거하고 (&lt;strong&gt;remove_existing&lt;/strong&gt;) 중복 제거된 fetch list를 생성한다(&lt;strong&gt;freegen&lt;/strong&gt;).
readdb, freegen은 Nutch 명령어이며 remove_existing은 파이썬으로 직접 구현했다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/14/2020-09-14-my-workflow.png&quot; alt=&quot;my-workflow&quot; /&gt;&lt;/p&gt;

&lt;p&gt;수정된 워크플로우에선 중복 fetch가 모두 사라지면서 수집시간이 2시간에서 30분 내외로 획기적으로 줄었다.
(그동안 중복 페이지들을 얼마나 많이 수집했던건지…ㄷㄷ)&lt;/p&gt;

&lt;h3 id=&quot;3-4-mapreduce-병렬처리-문제&quot;&gt;3-4. MapReduce 병렬처리 문제&lt;/h3&gt;
&lt;p&gt;위의 freegen 명령어를 사용하다가 Nutch 소스코드에 버그가 있다는 것을 발견했다.
Nutch의 github 이슈에 댓글을 달았더니 담당 개발자분이 알려줘서 고맙다고 답글을 달았다.
금새 이슈가 생성됐고 지금은 해결되었다.
이 부분은 다른 포스트로 자세히 다뤄볼 생각이다.
해당 이슈는 &lt;a href=&quot;https://issues.apache.org/jira/browse/NUTCH-2810&quot;&gt;NUTCH-2810&lt;/a&gt;를 참고&lt;/p&gt;

&lt;h3 id=&quot;3-5-배치-작업-스케줄링&quot;&gt;3-5. 배치 작업 스케줄링&lt;/h3&gt;
&lt;p&gt;Nutch 배치작업은 Apache Airflow로 스케줄링하고 있다.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;https://cwiki.apache.org/confluence/display/NUTCH/NutchTutorial&lt;/li&gt;
  &lt;li&gt;https://issues.apache.org/jira/browse/NUTCH-2706&lt;/li&gt;
  &lt;li&gt;https://www.slideshare.net/sebastian_nagel/aceu2014-snagelwebcrawlingnutch&lt;/li&gt;
  &lt;li&gt;https://issues.apache.org/jira/browse/NUTCH-2810&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="apache-nutch" /><category term="nutch" /><category term="java" /><category term="crawler" /><category term="airflow" /><summary type="html">1. Apache Nutch Apache Nutch는 Java 언어로 만들어진 분산형 웹 크롤러다. 현재는 널리 쓰이고 있는 Hadoop이 바로 이 Nutch의 하위 프로젝트에서 시작되었다. 최근 Nutch로 웹 크롤러를 구축하면서 소소하게 경험해본 것들을 기록해본다.</summary></entry><entry><title type="html">PySpark의 py4j 호환성 오류</title><link href="http://localhost:4000/apache-spark/pyspark-py4j-error/" rel="alternate" type="text/html" title="PySpark의 py4j 호환성 오류" /><published>2020-09-09T00:00:00+09:00</published><updated>2020-09-09T00:00:00+09:00</updated><id>http://localhost:4000/apache-spark/pyspark-py4j-error</id><content type="html" xml:base="http://localhost:4000/apache-spark/pyspark-py4j-error/">&lt;h2 id=&quot;1-py4jerror&quot;&gt;1. Py4JError&lt;/h2&gt;
&lt;p&gt;기존에 사용하던 Spark을 2.2.0 -&amp;gt; 2.4.6으로 변경했더니 Jupyter에서 PySpark이 정상적으로 동작하지 않는 오류가 발생했다.
실행한 코드는 아래와 같이 SparkSession을 생성하는 간단한 내용이다.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;pyspark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;sql&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;SparkSession&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;SparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;getOrCreate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;SparkSession을 생성하려고 하면 다음과 같이 Py4JError가 발생한다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Py4JError                                 Traceback (most recent call last)
&amp;lt;ipython-input-3-ce55329f3d67&amp;gt; in &amp;lt;module&amp;gt;()
----&amp;gt; 1 spark = SparkSession.builder.getOrCreate()
      2 spark

/opt/spark-2.4.6-bin-hadoop2.7/python/pyspark/sql/session.py in getOrCreate(self)
/opt/spark-2.4.6-bin-hadoop2.7/python/pyspark/context.py in getOrCreate(cls, conf)
/opt/spark-2.4.6-bin-hadoop2.7/python/pyspark/context.py in __init__(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)
/opt/spark-2.4.6-bin-hadoop2.7/python/pyspark/context.py in _ensure_initialized(cls, instance, gateway, conf)
/opt/spark-2.4.6-bin-hadoop2.7/python/pyspark/java_gateway.py in launch_gateway(conf)
/opt/spark-2.4.6-bin-hadoop2.7/python/pyspark/java_gateway.py in _launch_gateway(conf, insecure)
/data/venv/lib64/python3.6/site-packages/py4j/java_gateway.py in java_import(jvm_view, import_str)
/data/venv/lib64/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)
    321                 raise Py4JError(
    322                     &quot;An error occurred while calling {0}{1}{2}. Trace:\n{3}\n&quot;.
--&amp;gt; 323                     format(target_id, &quot;.&quot;, name, value))
    324         else:
    325             raise Py4JError(

Py4JError: An error occurred while calling None.None. Trace:
Authentication error: unexpected command. 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;2-pyspark의-jvm-연동&quot;&gt;2. PySpark의 JVM 연동&lt;/h2&gt;
&lt;p&gt;위 현상은 새로 설치한 spark의 pyspark shell에서는 발생하지 않는다.
기존에 사용하던 python 가상환경에서 pyspark을 import하여 사용할 때에만 발생한다.&lt;/p&gt;

&lt;p&gt;PySpark은 python으로 작성된 코드를 jvm에서 수행하기 위해 py4j 라이브러리를 사용한다.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;${SPARK_HOME}/python/pyspark/java_gateway.py&lt;/code&gt;를 보면 
py4j의 java_import 함수를 사용하여 필요한 클래스들을 jvm에 import한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;c1&quot;&gt;# Import the classes used by PySpark
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;java_import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gateway&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jvm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.spark.SparkConf&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;java_import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gateway&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jvm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.spark.api.java.*&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;java_import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gateway&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jvm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.spark.api.python.*&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;java_import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gateway&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jvm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.spark.ml.python.*&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;java_import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gateway&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jvm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.spark.mllib.api.python.*&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# TODO(davies): move into sql
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;java_import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gateway&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jvm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.spark.sql.*&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;java_import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gateway&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jvm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.spark.sql.api.python.*&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;java_import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gateway&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jvm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.spark.sql.hive.*&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;java_import&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gateway&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jvm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;scala.Tuple2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3-원인과-해결책&quot;&gt;3. 원인과 해결책&lt;/h2&gt;

&lt;p&gt;여기서 오류가 발생한 이유는 정말 사소한 것 때문이었다.
기존에 사용하던 PySpark을 위해 py4j를 설치했었는데,
신규 설치한 Spark이 요구하는 버전과 달라서 오류가 발생했던 것이다.&lt;/p&gt;

&lt;p&gt;기존 사용하던 python 가상환경에는 py4j 0.10.4 버전이 설치되어 있었다.
반면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;${SPARK_HOME}/python/setup.py&lt;/code&gt;에서 신규 설치한 pyspark이 요구하는 py4j 버전은 다음과 같다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;install_requires&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'py4j==0.10.7'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;요구하는 버전을 설치하여 정말 간단하게 해결할 수 있는 문제였다.&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;pip &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;py4j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;0.10.7
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="apache-spark" /><category term="spark" /><category term="pyspark" /><category term="py4j" /><summary type="html">1. Py4JError 기존에 사용하던 Spark을 2.2.0 -&amp;gt; 2.4.6으로 변경했더니 Jupyter에서 PySpark이 정상적으로 동작하지 않는 오류가 발생했다. 실행한 코드는 아래와 같이 SparkSession을 생성하는 간단한 내용이다.</summary></entry><entry><title type="html">HDP 2.6에서 Spark 업그레이드하기</title><link href="http://localhost:4000/apache-spark/hdp-spark-upgrade/" rel="alternate" type="text/html" title="HDP 2.6에서 Spark 업그레이드하기" /><published>2020-09-08T00:00:00+09:00</published><updated>2020-09-08T00:00:00+09:00</updated><id>http://localhost:4000/apache-spark/hdp-spark-upgrade</id><content type="html" xml:base="http://localhost:4000/apache-spark/hdp-spark-upgrade/">&lt;h2 id=&quot;1-spark-22의-import-버그&quot;&gt;1. Spark 2.2의 import 버그&lt;/h2&gt;
&lt;p&gt;현재 사용 중인 하둡 클러스터는 HDP 2.6이며 Spark은 2.2 버전을 제공하고 있다.
해당 버전은 spark-shell에서 정상적으로 import가 작동하지 않는 버그(&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-22393&quot;&gt;SPARK-22393&lt;/a&gt;)가 존재하므로 Zeppelin에서 제대로 Spark 코드를 수행할 수가 없었다.
따라서 해당 버그가 수정된 버전인 Spark 2.4 버전을 HDP 2.6에 설치해 보고자 한다.&lt;/p&gt;

&lt;h2 id=&quot;2-hdp에-외부-spark-연동하기-yarn-client&quot;&gt;2. HDP에 외부 Spark 연동하기 (yarn-client)&lt;/h2&gt;
&lt;h3 id=&quot;2-1-spark-246-다운로드-및-설치&quot;&gt;2-1. Spark 2.4.6 다운로드 및 설치&lt;/h3&gt;

&lt;p&gt;우선 Apache Ambari 관리모드에서 기존 Spark을 삭제한 뒤, Spark 신규 버전을 Master 노드에 다운로드하였다.
HDP 2.6에선 Hadoop 2.7을 사용하므로 &lt;strong&gt;Pre-built for Apache Hadoop 2.7&lt;/strong&gt;을 선택한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/08/2020-09-08-download-spark.png&quot; alt=&quot;download-spark&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-2-spark-envsh-및-spark_home-설정&quot;&gt;2-2. spark-env.sh 및 SPARK_HOME 설정&lt;/h3&gt;
&lt;p&gt;원하는 곳에 압축 해제한 뒤 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conf/spark-env.sh&lt;/code&gt; 파일을 열어 아래와 같이 수정한다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/hdp/2.6.3.0-235/hadoop
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_CONF_DIR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/hadoop/conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HADOOP_HOME&lt;/code&gt;은 HDP Hadoop이 설치된 경로이다.
Spark은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HADOOP_CONF_DIR}&lt;/code&gt; 하위의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yarn-site.xml&lt;/code&gt; 파일을 이용해 YARN과 연결할 수 있게 된다.&lt;/p&gt;

&lt;p&gt;또한, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.bashrc&lt;/code&gt; 파일을 열어 아래와 같이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SPARK_HOME&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PATH&lt;/code&gt; 환경변수를 설정해준다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;설치한 Spark 디렉토리 경로&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SPARK_HOME&lt;/span&gt;/bin:&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-3-spark-shell-실행&quot;&gt;2-3. spark-shell 실행&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bin/spark-shell&lt;/code&gt;을 실행하면 REPL 환경에서 Spark 프로그래밍을 할 수 있다.
별도의 옵션 없이 수행하면 standalone 모드로 동작한다. YARN과 연동하여 하둡 클러스터를 이용하려면 yarn-client 모드로 동작해야 한다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;./bin/spark-shell &lt;span class=&quot;nt&quot;&gt;--master&lt;/span&gt; yarn &lt;span class=&quot;nt&quot;&gt;--deploy-mode&lt;/span&gt; client
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-4-yarn-timeline-service-이슈&quot;&gt;2-4. YARN timeline-service 이슈&lt;/h3&gt;

&lt;p&gt;hdp에서 위와 같이 yarn-client 모드를 수행하면 다음과 같은 에러가  발생한다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java.lang.NoClassDefFoundError: com/sun/jersey/api/client/config/ClientConfig
  at org.apache.hadoop.yarn.client.api.TimelineClient.createTimelineClient(TimelineClient.java:55)
  at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.createTimelineClient(YarnClientImpl.java:181)
  at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.serviceInit(YarnClientImpl.java:168)
  at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
  at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:161)
  at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:57)
  at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:188)
  at org.apache.spark.SparkContext.&amp;lt;init&amp;gt;(SparkContext.scala:501)
  at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2520)
  at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
  at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
  at scala.Option.getOrElse(Option.scala:121)
  at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
  at org.apache.spark.repl.Main$.createSparkSession(Main.scala:106)
  ... 62 elided
Caused by: java.lang.ClassNotFoundException: com.sun.jersey.api.client.config.ClientConfig
  at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
  at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
  at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
  at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
  ... 76 more
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다행히도 이 오류는 &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-15343&quot;&gt;SPARK-15343&lt;/a&gt;에서 다뤄진 적이 있다.
이슈 내용을 정라하자면 핵심은 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;YARN의 timeline-service 기능과 관련하여 jersey 라이브러리를 사용하고 있다.&lt;/li&gt;
  &lt;li&gt;기존에 사용하던 HDP 환경에선 YARN과 Spark 모두 jersey 1.9 버전을 사용하고 있었으나, &lt;strong&gt;Spark 2.4는 2.22.2 버전을 사용하므로 서로 호환되지 않는다&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;YARN은 디폴트로 timeline-service 기능이 켜져있으므로 &lt;strong&gt;항상 jersey 호환성으로 인한 NoClassDefFoundError를 일으키게 된다&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;jira 이슈에서 제시되는 몇가지 해결책들이 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;timeline-service를 중지하기 위해 YARN 설정에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yarn.timeline-service.enabled&lt;/code&gt; 옵션을 false로 변경하거나&lt;/li&gt;
  &lt;li&gt;spark-shell을 수행할 때 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--conf spark.timeline-service.enabled=false&lt;/code&gt; 옵션을 추가해주거나&lt;/li&gt;
  &lt;li&gt;spark의 jars 디렉토리에 jersey 1.9 라이브러리를 넣어서 버전을 통일시켜주는 방법이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;YARN에 제출되는 다양한 애플리케이션들 중 오직 Spark만을 위해서 timeline-service 기능을 끄는 것은 다소 실용성이 떨어진다.
jersey의 버전을 강제적으로 통일했을 땐 부가적인 문제가 생길 가능성이 있으므로 여기서는 두번째 방안을 채택하기로 했다.
옵션을 디폴트로 설정하려면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conf/spark-defaults.conf&lt;/code&gt; 파일에 아래와 같이 추가해준다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spark.hadoop.yarn.timeline-service.enabled   false
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-5-yarn-application-has-already-ended-hdpversion-이슈&quot;&gt;2-5. YARN application has already ended! (hdp.version 이슈)&lt;/h3&gt;

&lt;p&gt;timeline-service 이슈를 해결했더니 이번에는 다음과 같은 에러가 발생했다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;20/09/08 19:42:53 ERROR cluster.YarnClientSchedulerBackend: The YARN application has already ended! Itmight have been killed or the Application Master may have failed to start. Check the YARN application logs for more details.
20/09/08 19:42:53 ERROR spark.SparkContext: Error initializing SparkContext.
org.apache.spark.SparkException: Application application_1599556837475_0006 failed 2 times due to AM Container for appattempt_1599556837475_0006_000002 exited with  exitCode: 1
For more detailed output, check the application tracking page: http://불라불라불라/cluster/app/application_1599556837475_0006 Then click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_e16_1599556837475_0006_02_000001
Exit code: 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;YARN에 작업이 제출된 즉시 애플리케이션이 종료된다.
원인을 찾느라 한참 헤맸는데 사실은 정말 단순한 이유였다.
HDP에선 Spark job을 제출할 때 java 옵션으로 HDP 버전을 명시해줘야 하는데,
HDP와는 별개로 설치한 Spark 패키지여서 이 부분을 생략했던 것이다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/55931970/how-can-i-run-spark-in-headless-mode-in-my-custom-version-on-hdp&quot;&gt;스택오버플로우&lt;/a&gt;에 올라온 답변을 참조하여 다음과 같이 옵션을 추가하였다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;./bin/spark-shell &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;--master&lt;/span&gt; yarn &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;--deploy-mode&lt;/span&gt; client &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;--conf&lt;/span&gt; spark.hadoop.yarn.timeline-service.enabled&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;--conf&lt;/span&gt; spark.driver.extraJavaOptions&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'-Dhdp.version=2.6.3.0-235'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;--conf&lt;/span&gt; spark.yarn.am.extraJavaOptions&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'-Dhdp.version=2.6.3.0-235'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;--conf&lt;/span&gt; spark.executor.extraJavaOptions&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'-Dhdp.version=2.6.3.0-235'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여기까지 수행한 끝에 HDP 2.6에서 yarn-client 모드로 Spark 2.4 버전을 사용할 수 있게 되었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/08/2020-09-08-spark-shell-result.jpeg&quot; alt=&quot;result&quot; /&gt;&lt;/p&gt;

&lt;p&gt;해당 옵션을 디폴트로 사용하려면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conf/spark-defaults.conf&lt;/code&gt;에 아래 라인들을 추가해준다.
참고로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.yarn.am.extraJavaOptions&lt;/code&gt; 옵션은 yarn-cluster 모드에선 효과가 없다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spark.driver.extraJavaOptions    -Dhdp.version=2.6.3.0-235
spark.yarn.am.extraJavaOptions   -Dhdp.version=2.6.3.0-235
spark.executor.extraJavaOptions  -Dhdp.version=2.6.3.0-235
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3-hdp에-spark-cluster-설치하기-yarn-cluster&quot;&gt;3. HDP에 Spark Cluster 설치하기 (yarn-cluster)&lt;/h2&gt;
&lt;h3 id=&quot;3-1-yarn-client-vs-yarn-cluster&quot;&gt;3-1. yarn-client vs. yarn-cluster&lt;/h3&gt;

&lt;p&gt;위처럼 yarn-client 모드로 사용할 땐 master 노드에만 spark을 설치하면 된다.
그러나 yarn-cluster 모드를 사용하려면 slave 노드들에도 spark이 설치되어야 한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;yarn-client&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/11/2020-09-11-yarn-client-mode.png&quot; alt=&quot;yarn-client&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;yarn-cluster&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/11/2020-09-11-yarn-cluster-mode.png&quot; alt=&quot;yarn-cluster&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 이미지에서 보듯이, client 모드와 cluster 모드의 가장 큰 차이는 spark driver의 위치다.
cluster 모드에선 spark driver가 application master에서 동작한다.
즉 클러스터 내부에서 spark driver가 생성되어야 한다.
모든 slave 노드들에 spark을 설치해줘야 하는 이유다.&lt;/p&gt;

&lt;h3 id=&quot;3-2-ssh-연결-설정&quot;&gt;3-2. ssh 연결 설정&lt;/h3&gt;

&lt;p&gt;spark cluster가 구성되려면 각 노드의 spark 계정끼리 ssh로 연결 가능해햐 한다.
ssh 키가 없다면 아래 명령어로 생성해준다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ssh-keygen
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;master 노드의 ssh public 키를 나머지 노드들에 복사해준다.&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ssh-copy-id &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;계정&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;@&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;서버IP&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;ssh포트번호&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그 후, 각 slave 장비에 접속하여 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.ssh/authorized_keys&lt;/code&gt; 파일의 권한을 확인해준다.&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;chmod &lt;/span&gt;600 ~/.ssh/authorized_keys
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-3-spark-cluster를-위한-설정&quot;&gt;3-3. Spark Cluster를 위한 설정&lt;/h3&gt;

&lt;p&gt;slave 노드들에 spark을 설치해주기 전에 master 노드의 spark에 몇가지 설정을 변경해주어야 한다.&lt;/p&gt;

&lt;h4 id=&quot;java-opts&quot;&gt;java-opts&lt;/h4&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conf/java-opts&lt;/code&gt; 파일을 생성하고 아래 라인을 추가한다.
yarn-cluster 모드에서도 hdp.version을 맞추기 위한 설정파일이다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;-Dhdp.version=2.6.3.0-235
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;spark-envsh&quot;&gt;spark-env.sh&lt;/h4&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conf/spark-env.sh&lt;/code&gt; 파일에 다음 라인들을 추가한다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SPARK_MASTER&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'{master 서버 IP}'&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SPARK_WORKER_PORT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;ssh포트번호&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SPARK_SSH_OPTS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'-p {ssh포트번호}'&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;JAVA_HOME&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;slaves&quot;&gt;slaves&lt;/h4&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conf/slaves.template&lt;/code&gt; 파일 이름을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conf/slaves&lt;/code&gt;로 변경하고 아래 라인들을 추가한다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{slave1 서버IP}
{slave2 서버IP}
{slave3 서버IP}
...(하략)...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;spark_shuffle&quot;&gt;spark_shuffle&lt;/h4&gt;
&lt;p&gt;이 부분은 Spark이 아니라 Ambari의 YARN 설정에서 수정해주어야 한다.&lt;/p&gt;

&lt;p&gt;Spark이 dynamicAllocation을 사용하려면 YARN의 NodeManager 설정에서 spark_shuffle 옵션을 추가해주어야 한다.&lt;/p&gt;

&lt;p&gt;그 다음 YARN이 spark_shuffle 기능을 사용할 수 있도록 class path를 입력해주어야 한다.
새로 설치한 Spark의 yarn 디렉토리에 spark-2.4.6-yarn-shuffle.jar 파일이 존재하므로
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;${SPARK_HOME}/yarn/*&lt;/code&gt; 와 같이 classpath를 입력해준다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/08/2020-09-08-yarn-spark-shuffle-setting.png&quot; alt=&quot;spark_shuffle_setting&quot; /&gt;&lt;/p&gt;

&lt;p&gt;설정 완료 후 YARN을 재시작한다.&lt;/p&gt;

&lt;h3 id=&quot;3-4-spark-cluster-설치&quot;&gt;3-4. Spark Cluster 설치&lt;/h3&gt;

&lt;p&gt;이제 master 노드의 spark을 압축하여 모든 slave 노드들의 동일한 경로에 복사/압축해제해준다.
각 노드의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.bashrc&lt;/code&gt;파일에 master 노드와 동일한 설정을 추가해준다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;설치한 Spark 디렉토리 경로&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SPARK_HOME&lt;/span&gt;/bin:&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;끝으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;JAVA_HOME&lt;/code&gt; 역시 확인해준다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-5-spark-cluster-실행&quot;&gt;3-5. Spark Cluster 실행&lt;/h3&gt;

&lt;p&gt;master 노드의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SPARK_HOME&lt;/code&gt;에서 다음 명령어로 spark cluster를 실행해준다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;./sbin/start-all.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;기존에 개발된 spark 프로그램이 yarn-cluster 모드에서 정상 동작하는 것까지 확인하였다.
여기까지 수행하면 Spark 2.4.6 설치가 완료된 것이다.&lt;/p&gt;

&lt;p&gt;웬만하면 Ambari나 Cloudera Manager가 제공해주는 버전을 그냥 쓰는게 정신건강에 이로울 것 같다.&lt;/p&gt;

&lt;h3 id=&quot;부록-zeppelin-설치&quot;&gt;(부록) Zeppelin 설치&lt;/h3&gt;
&lt;p&gt;hdp 2.6에서 제공하는 Zeppelin의 Spark interpreter는 2.4.6 버전을 지원하지 않으므로 Zeppelin 역시 삭제하고 별도로 설치해야 한다.
최신 버전인 &lt;strong&gt;0.9.0-preview2-bin-netinst&lt;/strong&gt; 으로 설치하고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conf/zeppelin-env.sh&lt;/code&gt;에 아래와 같은 설정들을 추가해줬다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;Java home 경로&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SPARK_MASTER&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;yarn-client
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ZEPPELIN_JAVA_OPTS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-Dhdp.version=2.6.3.0-235&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;={&lt;/span&gt;Spark 설치경로&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_CONF_DIR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/hadoop/conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;https://issues.apache.org/jira/browse/SPARK-22393&lt;/li&gt;
  &lt;li&gt;https://issues.apache.org/jira/browse/SPARK-15343&lt;/li&gt;
  &lt;li&gt;https://stackoverflow.com/questions/55931970/how-can-i-run-spark-in-headless-mode-in-my-custom-version-on-hdp&lt;/li&gt;
  &lt;li&gt;https://medium.com/@goyalsaurabh66/running-spark-jobs-on-yarn-809163fc57e2&lt;/li&gt;
  &lt;li&gt;https://kb.informatica.com/solution/23/pages/71/577764.aspx&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="apache-spark" /><category term="spark" /><category term="scala" /><category term="hdp" /><category term="yarn" /><summary type="html">1. Spark 2.2의 import 버그 현재 사용 중인 하둡 클러스터는 HDP 2.6이며 Spark은 2.2 버전을 제공하고 있다. 해당 버전은 spark-shell에서 정상적으로 import가 작동하지 않는 버그(SPARK-22393)가 존재하므로 Zeppelin에서 제대로 Spark 코드를 수행할 수가 없었다. 따라서 해당 버그가 수정된 버전인 Spark 2.4 버전을 HDP 2.6에 설치해 보고자 한다.</summary></entry><entry><title type="html">Spark Shell import 에러</title><link href="http://localhost:4000/apache-spark/sparkshell-import-error/" rel="alternate" type="text/html" title="Spark Shell import 에러" /><published>2020-09-07T00:00:00+09:00</published><updated>2020-09-07T00:00:00+09:00</updated><id>http://localhost:4000/apache-spark/sparkshell-import-error</id><content type="html" xml:base="http://localhost:4000/apache-spark/sparkshell-import-error/">&lt;h2 id=&quot;1-문제-발견&quot;&gt;1. 문제 발견&lt;/h2&gt;
&lt;p&gt;Zeppelin에서 Spark을 사용하다가 이해할 수 없는 에러를 보게 되었다.
아래는 “&lt;a href=&quot;https://github.com/sryza/aas/blob/master/ch08-geotime/src/main/scala/com/cloudera/datascience/geotime/RichGeometry.scala&quot;&gt;9가지 사례로 익히는 고급 스파크 분석&lt;/a&gt;” 책의 예제코드이다.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;com.esri.core.geometry.Geometry&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RichGeometry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;geometry&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Geometry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위 코드를 Zeppelin에서 수행하게 되면 아래와 같은 에러가 뜬다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/dhkdn9192/dhkdn9192.github.io/master/assets/images/posts/2020/09/07/2020-09-07-zeppelin-error.png&quot; alt=&quot;zeppelin-error&quot; /&gt;&lt;/p&gt;

&lt;p&gt;첫 줄의 java esri 라이브러리는 Zeppelin의 Spark interpreter 옵션에서 Dependencies 항목에 jar 파일 경로로 추가했다.
import 자체는 문제 없이 수행된다.
문제는 import되었음에도 Spark interpreter가 인식을 못 하는 것이다. (심지어 같은 paragraph에서 실행했다!)&lt;/p&gt;

&lt;p&gt;위 문제가 발생한 환경은 다음과 같다&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;name&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;version&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;OpenJDK&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1.8.0_191&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Scala&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2.11.8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Spark&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2.2.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;HDP&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2.6.3.0-235&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Zeppelin&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.7.3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;2-stackoverflow-검색&quot;&gt;2. StackOverflow 검색&lt;/h2&gt;

&lt;p&gt;Stackoverflow에서 검색을 하다 크게 2가지 해결 방법을 찾았다.&lt;/p&gt;

&lt;h3 id=&quot;2-1-세미콜론으로-라인-이어붙이기&quot;&gt;2-1. 세미콜론으로 라인 이어붙이기&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;세미콜론&lt;/em&gt;을 이용하여 import 구문과 class 선언 구문을 한 라인으로 이어 붙이는 방법이다. (…)
정상적으로 수행은 가능하지만 코드가 매우 기괴해진다.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;com.esri.core.geometry.Geometry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RichGeometry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;geometry&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Geometry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,...)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-2-싱글톤으로-감싸기&quot;&gt;2-2. 싱글톤으로 감싸기&lt;/h3&gt;

&lt;p&gt;import 구문부터 class 선언구문 전체를 하나의 싱글톤으로 감싼다.
싱글톤 내부에서 import하므로 정상적으로 class 선언이 가능해진다.
그러나 클래스를 직접 호출할 수 없고 싱글톤 내부에서 가져와야 한다.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MM&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;com.esri.core.geometry.Geometry&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RichGeometry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;geometry&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Geometry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;
두 가지 모두 마음에 드는 해결책은 아니다.
구체적으로 원인이 무엇인지, 근본적인 해결책은 어떤건지 자세히 알아봐야겠다.&lt;/p&gt;

&lt;h2 id=&quot;3-근본적인-원인과-해결책&quot;&gt;3. 근본적인 원인과 해결책&lt;/h2&gt;
&lt;p&gt;Zeppelin 상에서 발견해서 당연히 Zeppelin 상의 버그인 줄 알았는데 알고보니 Spark-Shell의 오류였다.
(좀 더 깊게 들어가면 Scala까지 가게 된다.)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-22393&quot;&gt;SPARK-22393&lt;/a&gt; 이슈에 따르면 Spark 2.x대에 들어서면서 발생한 버그다.
Scala 언어에서 2.11~2.12 버전 사이에 importHandler 관련 버그 픽스(&lt;a href=&quot;https://github.com/scala/bug/issues/9881&quot;&gt;SI-9880&lt;/a&gt;)가 있었는데 해당 이슈로 인해 Spark에도 import 관련 버그가 발생한 것으로 보인다.&lt;/p&gt;

&lt;p&gt;컨트리뷰터들 사이에서도 굉장히 난해한 버그였던 것 같다. 핵심만 정리하자면&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scala 2.11 에서 동작하는 Spark에서 해당 버그 발생함&lt;/li&gt;
  &lt;li&gt;Scala 2.12 에서는 importHandler 이슈가 해결됨에 따라 spark-shell 역시 정상적으로 동작함&lt;/li&gt;
  &lt;li&gt;spark-shell의 버그를 고치기 위해 Scala까지 수정하는 것은 매우 큰 작업이고 리스크가 크므로 실용적이지 않음&lt;/li&gt;
  &lt;li&gt;따라서 Scala의 fix를 적절히 이용하여 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkExprTyper&lt;/code&gt; 및 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SparkILoopInterpreter&lt;/code&gt;를 spark-shell에 추가하여 버그픽스함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;즉, Spark 2.3부터는 해당 이슈가 해결되었다.
Spark의 버전을 업그레이드하는 것이 가장 합리적인 해결책이다.&lt;/p&gt;

&lt;p&gt;문제가 있다면 내가 사용하는 HDP에서는 Spark 버전이 2.2라는 것이다.
HDP와는 별도로 Spark 최신버전을 설치하고 Zeppelin에 연동하는 방식으로 사용해야할 것 같다.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;https://github.com/sryza/aas&lt;/li&gt;
  &lt;li&gt;https://issues.apache.org/jira/browse/SPARK-22393&lt;/li&gt;
  &lt;li&gt;https://github.com/scala/bug/issues/9881&lt;/li&gt;
&lt;/ul&gt;</content><author><name>김동혁</name><email>dhkdn9192@naver.com</email></author><category term="apache-spark" /><category term="spark" /><category term="zeppelin" /><category term="scala" /><summary type="html">1. 문제 발견 Zeppelin에서 Spark을 사용하다가 이해할 수 없는 에러를 보게 되었다. 아래는 “9가지 사례로 익히는 고급 스파크 분석” 책의 예제코드이다.</summary></entry></feed>